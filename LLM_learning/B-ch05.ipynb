{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bf076af-50cb-46f1-9a0d-cd864e6920f2",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afe495a-a838-4737-b7ff-4306f5745c66",
   "metadata": {},
   "source": [
    "# Chapter 5: Pretraining on Unlabeled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22199548-14f6-4e0d-ad09-3ed240a45676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.8.4\n",
      "numpy version: 1.26.4\n",
      "tiktoken version: 0.8.0\n",
      "torch version: 2.5.0+cu118\n",
      "tensorflow version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\", \n",
    "        \"numpy\", \n",
    "        \"tiktoken\", \n",
    "        \"torch\",\n",
    "        \"tensorflow\" # For OpenAI's pretrained weights\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef65c2c-c2e8-4770-8b2c-6cabd8522cef",
   "metadata": {},
   "source": [
    "本章内容包括\n",
    "- 计算训练和验证集的损失，以评估在训练期间生成的LLM文本的质量\n",
    "- 实现一个训练函数并预训练LLM\n",
    "- 保存和加载模型权重以继续训练LLM\n",
    "- 从OpenAI加载预训练的权重"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76562d54-839d-469e-bc7a-58c19d33c472",
   "metadata": {},
   "source": [
    "在前几章中，我们实现了数据采样、注意力机制并编码了LLM架构。本章的核心重点是实现一个训练函数并预训练LLM。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04df775c-a82d-4a73-bbd3-64ef0e7e6a55",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/chapter-overview.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ac001c-dd58-48c0-a51b-4e11fb5695f8",
   "metadata": {},
   "source": [
    "- 本章涵盖的主题如下所示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7ce4b9-ae9f-47e1-8f20-2b0be7a413f3",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model--0.webp\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ba20cd-12e6-49ba-9b60-6da2b9250ae2",
   "metadata": {},
   "source": [
    "## 5.1 Evaluating generative text models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36352ccd-e52f-4379-a842-4521d2e18038",
   "metadata": {},
   "source": [
    "- 我们首先简要回顾一下如何使用前一章的代码来初始化一个GPT模型\n",
    "- 接着，我们讨论了用于评估大型语言模型的基本评价指标\n",
    "- 最后，在本节中，我们将这些评价指标应用于训练集和验证集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cf7e50-3f3c-441c-ba35-b622a0d21ce9",
   "metadata": {},
   "source": [
    "### 5.1.1 Using GPT to generate text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b84385-e08d-464f-9427-aa1c1a886960",
   "metadata": {},
   "source": [
    "- 我们使用前一章的代码来初始化一个GPT模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c032cae-d914-4011-8439-db85e2704118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch                        # 导入torch库\n",
    "from previous_chapters import GPTModel      # 从第4章导入GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {                 # GPT配置字典\n",
    "    \"vocab_size\": 50257,            # 词汇表大小\n",
    "    \"context_length\": 256,          #A 将上下文长度从1024缩短到256词元\n",
    "    \"emb_dim\": 768,                 # 嵌入维度\n",
    "    \"n_heads\": 12,                  # 注意力头数量\n",
    "    \"n_layers\": 12,                 # 层数\n",
    "    \"drop_rate\": 0.1,               #B 可能且常见的是将dropout设置为0。\n",
    "    \"qkv_bias\": False               # QKV偏置\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)              # 设置随机种子\n",
    "model = GPTModel(GPT_CONFIG_124M)   # 使用配置初始化模型\n",
    "model.eval()                        # 将模型设置为评估模式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e85b653-e79b-4e8a-953b-1bb722cec752",
   "metadata": {},
   "source": [
    "- 我们之前使用了0.1的dropout（随机失活率），但现在训练大型语言模型时不使用dropout已经相对常见了。\n",
    "- 现代的大型语言模型在`nn.Linear`层中用于查询（query）、键（key）和值（value）矩阵时也不使用偏置向量（这与早期的GPT模型不同），这是通过设置`\"qkv_bias\": False`来实现的。\n",
    "- 我们将上下文长度（`context_length`）减少到只有256个令牌，以降低训练模型所需的计算资源需求，而原始的具有1.24亿参数的GPT-2模型使用了1024个令牌。\n",
    "  - 这样做是为了让更多读者能够在他们的笔记本电脑上跟随并执行代码示例。\n",
    "  - 我们稍后也会从预训练权重中加载一个具有1024个令牌`context_length`（上下文长度）的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e982e0c1-7d17-447b-ba95-1c8ddf548d32",
   "metadata": {},
   "source": [
    "- 接下来，我们使用前一章中的 `generate_text_simple`函数来生成文本。\n",
    "- 此外，我们定义了两个实用函数，`text_to_token_ids` 和 `token_ids_to_text`，用于在本章中使用的令牌（token）和文本（text）表示之间的转换。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb892f19-cbac-4017-8f38-a1f7c1751b1e",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/gpt-process.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ee65fb6-42fb-4f2d-a0eb-829dcabc6b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken                    # 导入tiktoken库\n",
    "from previous_chapters import generate_text_simple # 从第4章导入generate_text_simple函数\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):   # 定义text_to_token_ids函数\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'}) # 编码文本，允许特殊词元\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # 添加批次维度\n",
    "    return encoded_tensor             # 返回编码后的张量\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer): # 定义token_ids_to_text函数\n",
    "    flat = token_ids.squeeze(0)       # 移除批次维度\n",
    "    return tokenizer.decode(flat.tolist()) # 解码为文本\n",
    "\n",
    "start_context = \"Every effort moves you\" # 设置初始上下文\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\") # 获取GPT-2的分词器编码\n",
    "\n",
    "token_ids = generate_text_simple(   # 调用generate_text_simple函数生成词元ID\n",
    "    model=model,                    # 模型\n",
    "    idx=text_to_token_ids(start_context, tokenizer), # 将初始上下文转换为词元ID\n",
    "    max_new_tokens=10,              # 最大新词元数\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]  # 上下文长度\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer)) # 打印生成的文本\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f556d56f-7005-41a3-a959-0d471ba5ff35",
   "metadata": {},
   "source": [
    "- 根据输出结果，很明显模型尚未生成连贯的文本，因为它还没有经过训练。\n",
    "- 要定义使文本 “连贯”或“高质量” 的标准，我们必须实现一种数值方法来评估生成的内容。这种方法将使我们能够在整个训练过程中监控和提高模型的性能。\n",
    "- 接下来的小节介绍了用于计算生成输出的损失度量的指标，我们可以使用这些指标来衡量训练进度。\n",
    "- 接下来的章节关于微调大型语言模型也会介绍额外的方法来衡量模型质量。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db1622a-5374-44e2-9447-a038f2d088da",
   "metadata": {},
   "source": [
    "### 5.1.2 Calculating the text generation loss: cross-entropy and perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0290e2d1-3dad-4041-8d3b-7343a75a4f74",
   "metadata": {},
   "source": [
    "- 假设我们有一个名为 `inputs` 的张量，其中包含了2个训练样本（行）的标记ID。\n",
    "- 与 `inputs` 对应，`targets` 包含了我们希望模型生成的目标标记ID。\n",
    "- 请注意，`targets`是将 `inputs` 向右移动了一个位置，正如我们在第2章实现数据加载器时所解释的那样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1e34341-230a-4ab0-90d9-ac7ccb62c31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8d473b-e887-480b-99fe-718a347da031",
   "metadata": {},
   "source": [
    "- 将 `inputs` 馈送到模型中，我们获得了2个输入样本的logits向量，每个样本包含3个标记。\n",
    "- 每个标记都是一个对应于词汇表大小的50,257维向量。\n",
    "- 应用softmax函数，我们可以将logits张量转换为具有相同维度的张量，其中包含概率分数。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f64f7dce-08b2-4402-8a54-8e1591f1dc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
    "print(probas.shape) # Shape: (batch_size, num_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e54b403-55ab-4824-bcb7-2ef5de529a3c",
   "metadata": {},
   "source": [
    "- 下图使用非常小的词汇量进行说明，概述了我们在上一章末尾讨论的如何将概率分数转换回文本。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a3938b-3a72-4420-911b-eb084eb884ad",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/proba-to-text.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b964b5c-08d2-4597-b6d1-6f154fd21fc8",
   "metadata": {},
   "source": [
    "- 如前一章所讨论，我们可以应用`argmax`函数将概率分数转换为预测的标记ID。\n",
    "- 上面的softmax函数为每个标记产生了一个50,257维的向量；`argmax`函数返回这个向量中最高概率分数的位置，这是给定标记的预测标记ID。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae9f1fd-fd77-4dce-8c76-113742a26196",
   "metadata": {},
   "source": [
    "- 由于我们有2个输入批次，每个批次有3个标记，我们获得了2乘以3的预测标记ID："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6eed4fc4-1324-4196-adc7-f250666f23b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c7dcf9-9f12-4c3b-8cb3-cac07097cf76",
   "metadata": {},
   "source": [
    "- 如果我们解码这些标记，我们会发现这些与我们希望模型预测的目标标记相当不同："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b430c452-9f53-48a2-b3c4-e90d0fdb7c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115da172-850f-43e9-a68d-f06f33e35a48",
   "metadata": {},
   "source": [
    "- 那是因为模型还没有经过训练。\n",
    "- 为了训练模型，我们需要知道它离正确预测（目标）有多远。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fe7868-62b9-48b5-8245-ca8cd9b5c2e0",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/proba-index.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4b2d43-c64a-47bc-a134-8ce69e414a9a",
   "metadata": {},
   "source": [
    "- 目标索引对应的标记概率如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89a89e78-1944-4cd9-93b8-8cad188ef9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03f8f2f-056f-4ead-ad46-6d3e22b29cc0",
   "metadata": {},
   "source": [
    "- 我们希望最大化所有这些值，使它们接近1的概率。\n",
    "- 在数学优化中，最大化概率分数的对数比最大化概率分数本身更容易[L8.2 Logistic Regression Loss Function](https://www.youtube.com/watch?v=GxJe0DZvydM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a528d62b-f6e2-41cd-90bd-9ed359eeaa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ddfb0a-5e71-423f-af30-11c4b24fffc9",
   "metadata": {},
   "source": [
    "- 接下来，我们计算平均对数概率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68993804-33b1-4894-9d9b-4866e95b6d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average probability for each token\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d885fd-6816-4ab0-bc5c-b068d64d6af6",
   "metadata": {},
   "source": [
    "- 目标是通过优化模型权重，使这个平均对数概率尽可能大。\n",
    "- 由于对数的存在，最大可能的值是0，而我们目前离0还很远。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3990e6bb-834f-4bbe-b197-ecf6f89d6183",
   "metadata": {},
   "source": [
    "- 在深度学习中，与其最大化平均对数概率，不如最小化负平均对数概率值，这是一种标准惯例；在我们的例子中，我们不会最大化-10.7940使其接近0，而是在深度学习中，我们会最小化10.7940使其接近0。\n",
    "- -10.7940的负值，即10.7940，也被称为深度学习中的交叉熵损失（cross-entropy loss）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86f2cf12-21c6-4a42-98e2-ecc291d52851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c0c996-9f8d-4a68-80b0-246b11f7a62e",
   "metadata": {},
   "source": [
    "- PyTorch已经实现了一个`cross_entropy`函数，该函数执行了前面的步骤。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71247e16-4519-4fe4-9d14-7b833a3716f5",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/cross-entropy.webp?123\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae7e2c3-1729-4977-ad69-8373a2138e05",
   "metadata": {},
   "source": [
    "- 在我们应用`cross_entropy`函数之前，让我们检查一下logits（模型输出的原始分数）和targets（目标标签）的形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64c1a6ab-21c1-4543-84b1-e98b12517b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276b1720-0b2b-42e5-83f0-bc471f9df90d",
   "metadata": {},
   "source": [
    "- 在PyTorch中，对于`cross_entropy`函数，我们希望将这些张量在批次维度上合并以展平它们："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66d75fdf-7911-42a0-91f8-15d7243401bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)  # 将logits展平\n",
    "targets_flat = targets.flatten()  # 将目标展平\n",
    "print(\"Flattened logits:\", logits_flat.shape)  # 打印展平后的logits形状\n",
    "print(\"Flattened targets:\", targets_flat.shape)  # 打印展平后的目标形状"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3404a83-5eb1-4748-9fd1-a22449baddcc",
   "metadata": {},
   "source": [
    "- 请注意，目标是标记ID，它们也代表在logits张量中我们想要最大化的索引位置。\n",
    "- PyTorch中的`cross_entropy`函数会自动处理对logits中要最大化的标记索引应用softmax和对数概率计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38ce2d7d-040a-43dc-acf5-2d32b2b5b991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847d2267-f494-4de6-91f9-41d10f442eb4",
   "metadata": {},
   "source": [
    "- 与交叉熵损失相关的概念是大型语言模型（LLM）的困惑度（perplexity）。\n",
    "- 困惑度简单地说是交叉熵损失的指数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39c163ca-e617-4a73-964c-c92a1191e159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5194ced-5a5a-44a3-9ed0-5805064e1c3d",
   "metadata": {},
   "source": [
    "- 困惑度通常被认为更易于解释，因为它可以被理解为模型在每一步不确定的有效词汇量大小（在上面的例子中，这将是48,725个单词或标记）。\n",
    "- 换句话说，困惑度提供了一个衡量模型预测的概率分布与数据集中单词实际分布匹配程度的指标。\n",
    "- 与损失函数类似，较低的困惑度表明模型预测更接近实际分布。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa37fc8a-eef0-4a0d-a870-d4f8274321fe",
   "metadata": {},
   "source": [
    "### 5.1.3 Calculating the training and validation set losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91d4041-2361-4ba7-9041-a281c57e38d7",
   "metadata": {},
   "source": [
    "- 我们使用一个相对较小的数据集（一个短篇故事）来训练大型语言模型。\n",
    "- 原因如下:\n",
    "  - 你可以在没有合适GPU的笔记本电脑上在几分钟内运行这些代码示例。\n",
    "  - 训练相对较快完成（几分钟而不是几周）。\n",
    "  - 我们使用公共领域的文本，这些文本可以包含在这个GitHub仓库中，而不会违反任何使用权或使仓库大小膨胀。\n",
    "\n",
    "- 例如，训练一个拥有70亿参数的Llama 2模型，该模型在A100 GPU上需要184,320个GPU小时，处理2万亿词元。\n",
    "  - 在撰写本文时，AWS上8xA100云服务器的每小时成本大约为30美元。\n",
    "  - 因此，通过粗略计算，训练这个大型语言模型的成本大约为690000美元。\n",
    "\n",
    " \n",
    "- 以下代码加载我们在第2章中使用的\"The Verdict\"短篇小说："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af7f5777-ee45-4ed2-824a-bd4a405c8c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"the-verdict.txt\"  # 文件路径\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:  # 以读模式打开文件\n",
    "    text_data = file.read()  # 读取文件内容"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3ec2aa-911a-4354-94fb-c0f5e2d0444f",
   "metadata": {},
   "source": [
    "- 通过打印前100个和最后100个单词来快速检查文本是否加载正常。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f796da3f-7552-4e90-84ee-fc40e8ec8e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5983126e-eb4e-4e9c-9abf-27ce24bc4f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dfcdbd9f-8c2e-4e62-a725-79dbd5ba02f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da399902-abeb-490e-bf63-e9a07457618c",
   "metadata": {},
   "source": [
    "- 只有5145个词元，这段文本可能看起来太小，不适合训练LLM，但如前所述，这是为了教育目的，以便我们可以在几分钟内运行代码，而不是几周。\n",
    "- 此外，我们将在本章末尾从OpenAI加载预训练权重到我们的GPTModel代码中。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4b1c91-ca4e-4f79-b024-4ec8d061d4ea",
   "metadata": {},
   "source": [
    "- 接下来，我们将数据集划分为训练集和验证集，并使用第2章中的数据加载器为LLM训练准备批次。\n",
    "- 为了可视化目的，下图假设`max_length=6`，但对于训练加载器，我们将`max_length`设置为LLM支持的上下文长度。\n",
    "- 下图仅显示输入标记，以简化说明。\n",
    "    - 由于我们训练LLM来预测文本中的下一个单词，目标看起来与这些输入相同，只是目标在位置上向后移动了一个位置。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71b5dba-6d03-47d9-9b6f-b0d23c361cce",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/batching.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61256e74-4384-4938-8844-f1ef24b01e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import create_dataloader_v1\n",
    "import torch \n",
    "\n",
    "train_ratio = 0.90  # 训练集比例\n",
    "split_idx = int(train_ratio * len(text_data))  # 计算分割索引\n",
    "train_data = text_data[:split_idx]  # 获取训练数据\n",
    "val_data = text_data[split_idx:]  # 获取验证数据\n",
    "\n",
    "torch.manual_seed(123)  # 设置随机种子\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,  # 训练数据\n",
    "    batch_size=2,  # 批大小\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],  # 最大长度\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],  # 步幅\n",
    "    drop_last=True,  # 丢弃最后一个不完整批次\n",
    "    shuffle=True,  # 是否打乱数据\n",
    "    num_workers=0  # 工作线程数\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,  # 验证数据\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e71cf1-6e74-4606-b62c-630c6fb8ab35",
   "metadata": {},
   "source": [
    "- 我们使用相对较小的批次大小来减少计算资源需求，而且数据集本身非常小。\n",
    "- 例如，Llama 2是使用1024的批次大小进行训练的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ee4ed1-b73d-4502-806c-8487ce341bce",
   "metadata": {},
   "source": [
    "- 作为可选检查，我们可以遍历数据加载器，以确保它们已正确创建："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e6dbbb70-bf1b-4bb9-9ff7-02879a92b420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")  # 打印训练加载器\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)  # 打印每个批次的形状\n",
    "\n",
    "print(\"\\nValidation loader:\")  # 打印验证加载器\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)  # 打印每个批次的形状"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc3cc66-a732-4359-929e-34bce46fab0f",
   "metadata": {},
   "source": [
    "- 根据前面的代码输出，我们有9个训练集批次，每个批次包含2个样本和256个词元。\n",
    "- 由于我们只分配了10%的数据进行验证，因此只有一个由2个输入示例组成的验证批次。\n",
    "- 如预期的那样，输入数据（x）和目标数据（y）具有相同的形状（批大小乘以每个批次中的词元数），因为目标是将输入偏移一个位置。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e398766-acf0-4155-9aee-5428d90194e4",
   "metadata": {},
   "source": [
    "- 另一个可选的检查，以确保标记大小在预期的范围内："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "496c2993-e26c-4254-b1c4-674c57692145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d18d53-4668-4401-bf13-3024ff51b379",
   "metadata": {},
   "source": [
    "- 接下来，我们实现一个实用函数，以计算通过训练和验证加载器返回的给定批次的交叉熵损失\n",
    "- 此外，我们实现了第二个实用函数，用于计算数据加载器中用户指定数量批次的损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ed20151-deb3-4065-a09d-23eb801b9375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):  # 定义计算批次损失的函数\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)  # 将输入和目标批次转移到设备上\n",
    "    logits = model(input_batch)  # 模型计算logits\n",
    "    loss = torch.nn.functional.cross_entropy(  # 计算交叉熵损失\n",
    "        logits.flatten(0, 1), target_batch.flatten()  # 展平logits和目标批次\n",
    "    )\n",
    "    return loss  # 返回损失\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):  # 定义计算加载器损失的函数\n",
    "    total_loss = 0.  # 初始化总损失为0\n",
    "    if len(data_loader) == 0:  # 如果加载器为空\n",
    "        return float(\"nan\")  # 返回NaN\n",
    "    elif num_batches is None:  # 如果未指定批次数\n",
    "        num_batches = len(data_loader)  # 使用加载器中的批次数\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))  # 限制批次数为加载器中的批次数\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):  # 遍历加载器中的批次\n",
    "        if i < num_batches:  # 如果未达到指定批次数\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)  # 计算批次损失\n",
    "            total_loss += loss.item()  # 累加损失\n",
    "        else:\n",
    "            break  # 超过指定批次数则退出\n",
    "    return total_loss / num_batches  # 返回平均损失"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb79770-3790-4933-bb4f-d032307bb754",
   "metadata": {},
   "source": [
    "- 默认情况下，calc_loss_batch函数遍历给定数据加载器中的所有批次，将损失累加到total_loss变量中，然后计算并平均所有批次的损失。\n",
    "- 或者，我们可以通过num_batches指定较小的批次数，以加快模型训练期间的评估。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0519b99d-b17f-4c60-93e6-2813fbe68ec8",
   "metadata": {},
   "source": [
    "现在让我们来看一下这个calc_loss_batch函数的实际应用，将其应用于训练和验证集加载器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5abe70ab-caeb-4f69-9c16-6ea6f71f36f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.98758347829183\n",
      "Validation loss: 10.981106758117676\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device) \n",
    "\n",
    "\n",
    "torch.manual_seed(123) \n",
    "\n",
    "with torch.no_grad():   #禁用梯度计算以提高效率\n",
    "    train_loss = calc_loss_loader(train_loader, model, device) # 计算训练集损失\n",
    "    val_loss = calc_loss_loader(val_loader, model, device) # 计算验证集损失\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a6a182-c149-4c63-8530-85ca0ed8ed38",
   "metadata": {},
   "source": [
    "- 损失值相对较高，因为模型尚未训练。相比之下，如果模型学会生成训练和验证集中出现的下一个词元，损失将接近0。\n",
    "- 现在我们有了一种衡量生成文本质量的方法，在下一节中，我们训练LLM以减少这种损失，从而更好地生成文本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5f3ba0-1d79-4f27-8796-500ee1562e20",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model-1.webp\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc31c4bd-f3c0-49c2-80e8-abde8960a16e",
   "metadata": {},
   "source": [
    "## 5.2 Training an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3476b386-874e-4012-a6d3-78960f311f59",
   "metadata": {},
   "source": [
    "- 在这一节中，我们实现了训练LLM的代码。\n",
    "- 我们专注于一个简单的训练函数（如果您对使用更先进的技术增强这个训练函数感兴趣，如学习率预热、余弦退火和梯度裁剪，请参考附录D）。[Appendix D](../../appendix-D/01_main-chapter-code)\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/train-steps.webp\" width=300px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e538844d-4cdf-44f0-b084-ba378aae1488",
   "metadata": {},
   "source": [
    "- PyTorch中训练深度神经网络的典型训练循环包括几个步骤，在几个时期内迭代训练集中的批次。在每个循环中，我们计算每个训练集批次的损失以确定损失梯度，使用这些梯度来更新模型权重，从而使训练集损失最小化。\n",
    "- 流程图描述了一个典型的PyTorch神经网络训练工作流，我们用它来训练LLM。它概述了八个步骤，从迭代每个周期、处理批次、重置和计算梯度、更新权重，到以打印损失和生成文本示例等监控步骤结束。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4294acd3-8fbf-44d1-8ecf-53012b425e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []  # 初始化列表以跟踪损失和看到的词元\n",
    "    tokens_seen, global_step = 0, -1  # 初始化词元计数和全局步数\n",
    "\n",
    "    for epoch in range(num_epochs):  # 开始主要训练循环\n",
    "        model.train()  # 设置模型为训练模式\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:  # 遍历训练数据\n",
    "            optimizer.zero_grad() # 重置前一批次迭代的梯度\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device) # 计算批次损失\n",
    "            loss.backward() #  计算损失梯度\n",
    "            optimizer.step() # 使用损失梯度更新模型权重\n",
    "            tokens_seen += input_batch.numel()  \n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:  # 可选的评估步骤\n",
    "                train_loss, val_loss = evaluate_model(  # 评估模型性能\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)  # 添加训练损失到列表\n",
    "                val_losses.append(val_loss)  # 添加验证损失到列表\n",
    "                track_tokens_seen.append(tokens_seen)  # 记录看到的词元数\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"  # 打印当前训练信息\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "        generate_and_print_sample(  # 生成并打印样本\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen  # 返回训练和验证损失及词元计数\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    with torch.no_grad():  # 禁用梯度跟踪\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)   # 计算训练集损失\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)   # 计算验证集损失\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    return train_loss, val_loss  # 返回训练和验证损失\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]  # 获取上下文大小\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)   # 将文本转换为词元ID并移动到设备\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(  # 生成文本词元ID\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)  # 将词元ID转换为文本\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # 打印生成的文本，以紧凑格式显示\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84560a04-2c6c-4aaf-a846-a142cc9f903d",
   "metadata": {},
   "source": [
    "- Adam优化器是训练深度神经网络的常用选择。\n",
    "- AdamW是Adam的一种变体，它改进了权重衰减方法，旨在通过惩罚较大的权重来最小化模型复杂性并防止过拟合。\n",
    "- 这一调整使得AdamW能够实现更有效的正则化和更好的泛化，因此在LLMs的训练中经常使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00955e5b-4402-4805-998c-ee2a69b040d0",
   "metadata": {},
   "source": [
    "- 让我们通过使用AdamW优化器和之前定义的train_model_simple函数训练一个GPTModel实例10个周期来实际演示这一切。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "afb53378-af69-4be3-985f-d82e987f7a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.830, Val loss 9.927\n",
      "Ep 1 (Step 000005): Train loss 8.133, Val loss 8.335\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.770, Val loss 7.048\n",
      "Ep 2 (Step 000015): Train loss 6.497, Val loss 6.573\n",
      "Every effort moves you, and,, and, and,,,,, and, and,,,,,,,,,,,,,, and,,,, and,, and,,,,, and,,,,,,\n",
      "Ep 3 (Step 000020): Train loss 5.579, Val loss 6.490\n",
      "Ep 3 (Step 000025): Train loss 4.732, Val loss 6.387\n",
      "Every effort moves you, and to the picture.                      \"I, and the of the of the's the honour, and, and I had been, and I\n",
      "Ep 4 (Step 000030): Train loss 5.284, Val loss 6.360\n",
      "Ep 4 (Step 000035): Train loss 3.855, Val loss 6.258\n",
      "Every effort moves you of the to the picture--as of the picture--as I had been \" it was his \" I was the     \"I was his I had been the his pictures--and it the picture and I had been the picture of\n",
      "Ep 5 (Step 000040): Train loss 3.667, Val loss 6.196\n",
      "Every effort moves you know the \"Oh, and he was not the fact by his last word.         \"I was.      \"Oh, I felt a little a little the    \n",
      "Ep 6 (Step 000045): Train loss 3.600, Val loss 6.139\n",
      "Ep 6 (Step 000050): Train loss 2.383, Val loss 6.112\n",
      "Every effort moves you know; and my dear, and he was not the fact with a little of the house of the fact of the fact, and.                       \n",
      "Ep 7 (Step 000055): Train loss 2.336, Val loss 6.138\n",
      "Ep 7 (Step 000060): Train loss 2.696, Val loss 6.179\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I looked--as of the fact, and I felt him--his back his head to the donkey. \"Oh, and_--because he had always _\n",
      "Ep 8 (Step 000065): Train loss 1.596, Val loss 6.176\n",
      "Ep 8 (Step 000070): Train loss 1.346, Val loss 6.178\n",
      "Every effort moves you?\" \"I didn't bear the picture--I told me.  \"I looked up, and went on groping and Mrs. I was back the head to look up at the honour being _mine_--because he was when I\n",
      "Ep 9 (Step 000075): Train loss 1.100, Val loss 6.277\n",
      "Ep 9 (Step 000080): Train loss 0.672, Val loss 6.281\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.531, Val loss 6.325\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to the donkey again. I saw that, and down the room, when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)  # 设置随机种子\n",
    "model = GPTModel(GPT_CONFIG_124M)  # 初始化模型\n",
    "model.to(device)  # 将模型移动到设备\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)  # 使用AdamW优化器\n",
    "num_epochs = 10  # 训练周期数\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(  # 调用train_model_simple函数\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=1,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a537c5-08e1-496f-b92e-f50ef70ff792",
   "metadata": {},
   "source": [
    "- 根据训练期间打印的结果，训练损失显著改善，从9.830开始收敛到0.531。模型的语言技能大大提高。\n",
    "- 起初，模型只能在起始上下文（“Every effort moves you”）后附加逗号或重复“and”这个词。在训练结束时，它可以生成语法正确的文本。\n",
    "- 与训练集损失相似，我们可以看到验证损失开始时很高（9.927），并在训练过程中逐渐减少。然而，它从未变得像训练集损失那样小，并在第10周期后保持在6.325。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a1af239f-12a6-4a8c-b3ba-4203be865f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABVhElEQVR4nO3deXxM1/vA8c9M9n0jm6wIEUFI7PuuRatqa1Gqraq921dbraJfVFuqrVarv5Z+i1JrtUUtJWisIcQWSyMbkSCySiKZ+/tjZGLEkpCYSTzv12temTn33DvPXJFnzrnnnqNSFEVBCCGEEEZJbegAhBBCCHF3kqiFEEIIIyaJWgghhDBikqiFEEIIIyaJWgghhDBikqiFEEIIIyaJWgghhDBikqiFEEIIIyaJWgghhDBikqiFqCJUKhXr1q0zdBhCiHImiVoII6FSqe75GD58uKFDFEIYgKmhAxBCaF28eFH3fMWKFUyZMoWYmBhdmZWVlSHCEkIYmLSohTAS7u7uuoeDgwMqlUqvbNmyZdSqVQtzc3Pq1q3Lzz//fM/jTZ8+HTc3N6KiogCIiIigXbt2WFlZ4e3tzfjx48nOztbV9/PzY+bMmYwYMQI7Ozt8fHxYuHChbnt+fj5jx47Fw8MDS0tL/Pz8mDVr1l3ff8eOHTRr1gwbGxscHR1p3bo1cXFxuu2///47oaGhWFpaUrNmTaZNm0ZBQYFue3p6OiNHjsTV1RV7e3s6derEkSNHdNunTp1KSEgIP//8M35+fjg4ODBo0CAyMzNLfc6FqAwkUQtRCaxdu5YJEybw5ptvcuzYMV599VVefPFFtm/fXqKuoihMmDCBH374gd27dxMSEkJ0dDTdu3enb9++HD16lBUrVrB7927Gjh2rt++cOXMICwvj8OHDjB49mtdee41Tp04B8OWXX7J+/Xp+/fVXYmJiWLJkCX5+fneMt6CggD59+tC+fXuOHj3Knj17GDlyJCqVCoC//vqLIUOGMH78eE6cOMF3333H4sWLmTFjhu4z9OzZk+TkZDZs2EBkZCRNmjShc+fOXL16Vfc+586dY926dfzxxx/88ccfhIeH8/HHH5fHKRfCeChCCKOzaNEixcHBQfe6VatWyiuvvKJXp3///sqTTz6pew0oK1euVIYMGaIEBgYqCQkJum1Dhw5VRo4cqbf/rl27FLVarVy/fl1RFEXx9fVVhgwZotuu0WgUV1dXZcGCBYqiKMq4ceOUTp06KRqN5r7xX7lyRQGUHTt23HF727ZtlZkzZ+qV/fzzz4qHh4eiKIqybds2xd7eXsnNzdWrU6tWLeW7775TFEVRPvzwQ8Xa2lrJyMjQbX/77beV5s2b3zc+ISoTuUYtRCVw8uRJRo4cqVfWunVrvvjiC72y119/HQsLC/bu3Uu1atV05ZGRkZw9e5alS5fqyhRFQaPREBsbS7169QBo2LChbntR13tKSgoAw4cPp2vXrtStW5cePXrQq1cvunXrdsd4nZ2dGT58ON27d6dr16506dKFAQMG4OHhoYvnwIEDuhY0QGFhIbm5ueTk5BAZGUlWVhYuLi56x71+/Trnzp3Tvfbz88POzk732sPDQxevEFWFJGohKomibuMiiqKUKOvatSu//PILf/31F4MHD9aVazQaXn31VcaPH1/iuD4+PrrnZmZmJd5To9EA0KRJE2JjY9m4cSNbt25lwIABdOnShVWrVt0x3kWLFjF+/Hg2bdrEihUreP/999myZQstWrRAo9Ewbdo0+vbtW2I/S0tLNBoNHh4e7Nixo8R2R0fHUsUrRFUhiVqISqBevXrs3r2bF154QVcWERGhawkXeeqpp+jduzfPP/88JiYmDBo0CNAm2ePHj1O7du2HisPe3p6BAwcycOBA+vXrR48ePbh69SrOzs53rN+4cWMaN27Mu+++S8uWLVm2bBktWrSgSZMmxMTE3DWeJk2akJycjKmp6V2vgwvxuJBELUQl8PbbbzNgwADdgKrff/+dNWvWsHXr1hJ1n3nmGX7++WeGDh2Kqakp/fr1Y9KkSbRo0YIxY8bwyiuvYGNjw8mTJ9myZQtfffVVqWL4/PPP8fDwICQkBLVazcqVK3F3d9dr4RaJjY1l4cKFPPXUU3h6ehITE8Pp06d1XzSmTJlCr1698Pb2pn///qjVao4ePUp0dDT//e9/6dKlCy1btqRPnz7Mnj2bunXrcuHCBTZs2ECfPn0ICwt7qPMpRGUiiVqISqBPnz588cUXfPrpp4wfPx5/f38WLVpEhw4d7li/X79+aDQahg4dilqtpm/fvoSHhzN58mTatm2LoijUqlWLgQMHljoGW1tbZs+ezZkzZzAxMaFp06Zs2LABtbrkzSPW1tacOnWKn376iStXruDh4cHYsWN59dVXAejevTt//PEH06dP55NPPsHMzIzAwEBefvllQNuFvWHDBiZPnsyIESNITU3F3d2ddu3a4ebmVvYTKEQlplIURTF0EEIIIYS4M7mPWgghhDBikqiFEEIIIyaJWgghhDBikqiFEEIIIyaJWgghhDBikqiFEEIIIyaJ+i6++eYb/P39sbS0JDQ0lF27dhk6JIPbuXMnvXv3xtPTE5VKxbp16/S2K4rC1KlT8fT0xMrKig4dOnD8+HG9Onl5eYwbN45q1aphY2PDU089RWJiol6dtLQ0hg4dioODAw4ODgwdOpRr167p1YmPj6d3797Y2NhQrVo1xo8fT35+fkV87Edm1qxZNG3aFDs7O1xdXenTp4/eetQg5/hhLViwgIYNG2Jvb4+9vT0tW7Zk48aNuu1yfsvXrFmzUKlUTJw4UVcm5/gBGGw5ECO2fPlyxczMTPn++++VEydOKBMmTFBsbGyUuLg4Q4dmUBs2bFAmT56srF69WgGUtWvX6m3/+OOPFTs7O2X16tVKdHS0MnDgQMXDw0NvdaNRo0YpNWrUULZs2aIcOnRI6dixo9KoUSOloKBAV6dHjx5KcHCwEhERoURERCjBwcFKr169dNsLCgqU4OBgpWPHjsqhQ4eULVu2KJ6ensrYsWMr/BxUpO7duyuLFi1Sjh07pkRFRSk9e/ZUfHx8lKysLF0dOccPZ/369cqff/6pxMTEKDExMcp7772nmJmZKceOHVMURc5vedq/f7/i5+enNGzYUJkwYYKuXM5x2UmivoNmzZopo0aN0isLDAxU3nnnHQNFZHxuT9QajUZxd3dXPv74Y11Zbm6u4uDgoHz77beKoijKtWvXFDMzM2X58uW6OklJSYparVY2bdqkKIqinDhxQgGUvXv36urs2bNHAZRTp04piqL9wqBWq5WkpCRdnV9++UWxsLBQ0tPTK+TzGkJKSooCKOHh4YqiyDmuKE5OTsr//d//yfktR5mZmUpAQICyZcsWpX379rpELef4wUjX923y8/OJjIwssXxft27diIiIMFBUxi82Npbk5GS982ZhYUH79u115y0yMpIbN27o1fH09CQ4OFhXZ8+ePTg4ONC8eXNdnRYtWuDg4KBXJzg4GE9PT12d7t27k5eXR2RkZIV+zkcpPT0dQLfghZzj8lVYWMjy5cvJzs6mZcuWcn7L0ZgxY+jZsyddunTRK5dz/GBkru/bXL58mcLCwhLzCbu5uZGcnGygqIxf0bm503mLi4vT1TE3N8fJyalEnaL9k5OTcXV1LXF8V1dXvTq3v4+TkxPm5uZV5t9IURTeeOMN2rRpQ3BwMCDnuLxER0fTsmVLcnNzsbW1Ze3atQQFBen+wMv5fTjLly/n0KFDHDhwoMQ2+R1+MJKo76I0a/+Kkh7kvN1e5071H6ROZTZ27FiOHj3K7t27S2yTc/xw6tatS1RUFNeuXWP16tUMGzaM8PBw3XY5vw8uISGBCRMmsHnzZiwtLe9aT85x2UjX922qVauGiYlJiW9cKSkpsmrPPbi7uwPc87y5u7uTn59PWlraPetcunSpxPFTU1P16tz+Pmlpady4caNK/BuNGzeO9evXs337dry8vHTlco7Lh7m5ObVr1yYsLIxZs2bRqFEjvvjiCzm/5SAyMpKUlBRCQ0MxNTXF1NSU8PBwvvzyS0xNTXWfTc5x2Uiivo25uTmhoaFs2bJFr3zLli20atXKQFEZP39/f9zd3fXOW35+PuHh4brzFhoaipmZmV6dixcvcuzYMV2dli1bkp6ezv79+3V19u3bR3p6ul6dY8eOcfHiRV2dzZs3Y2FhQWhoaIV+zoqkKApjx45lzZo1/P333/j7++ttl3NcMRRFIS8vT85vOejcuTPR0dFERUXpHmFhYQwePJioqChq1qwp5/hBPNqxa5VD0e1ZP/zwg3LixAll4sSJio2NjXL+/HlDh2ZQmZmZyuHDh5XDhw8rgDJ37lzl8OHDutvWPv74Y8XBwUFZs2aNEh0drTz33HN3vO3Cy8tL2bp1q3Lo0CGlU6dOd7ztomHDhsqePXuUPXv2KA0aNLjjbRedO3dWDh06pGzdulXx8vKqlLdd3Oq1115THBwclB07digXL17UPXJycnR15Bw/nHfffVfZuXOnEhsbqxw9elR57733FLVarWzevFlRFDm/FeHWUd+KIuf4QUiivouvv/5a8fX1VczNzZUmTZrobpF5nG3fvl0BSjyGDRumKIr21osPP/xQcXd3VywsLJR27dop0dHRese4fv26MnbsWMXZ2VmxsrJSevXqpcTHx+vVuXLlijJ48GDFzs5OsbOzUwYPHqykpaXp1YmLi1N69uypWFlZKc7OzsrYsWOV3Nzcivz4Fe5O5xZQFi1apKsj5/jhjBgxQvf/unr16krnzp11SVpR5PxWhNsTtZzjslMpiqIYpi0vhBBCiPuRa9RCCCGEEZNELYQQQhgxSdRCCCGEEZNELYQQQhgxSdRCCCGEEZNELYQQQhgxSdT3kJeXx9SpU8nLyzN0KFWSnN+KJee34sk5rlhyfrXkPup7yMjIwMHBgfT0dOzt7Q0dTpUj57diyfmteHKOK5acXy1pUQshhBBGTBK1EEIIYcSq/HrUBQUFHD58GDc3N9Tqsn0vyczMBCApKYmMjIyKCO+xJue3Ysn5rXhyjitWVT6/Go2GS5cu0bhxY0xN752Kq/w16gMHDtCsWTNDhyGEEEKUsH//fpo2bXrPOlW+RV20QPj+/fvx8PAwcDRCCCGEdo3tZs2a6XLUvVT5RF3U3e3h4YGXl5eBoxFCCCGKleaSrEEHk+3cuZPevXvj6emJSqVi3bp1etsVRWHq1Kl4enpiZWVFhw4dOH78uGGCFUIIIQzAoIk6OzubRo0aMX/+/Dtu/+STT5g7dy7z58/nwIEDuLu707VrV90AAyGEEKKqM2jX9xNPPMETTzxxx22KojBv3jwmT55M3759Afjpp59wc3Nj2bJlvPrqq48yVCGEEMIgjPYadWxsLMnJyXTr1k1XZmFhQfv27YmIiLhros7Ly9Obbk5a30KIsigsLOTGjRuGDkNUcmZmZpiYmJTLsYw2UScnJwOUGBHn5uZGXFzcXfebNWsW06ZNq9DYhBBVj6IoJCcnc+3aNUOHIqoIR0dH3N3dUalUD3Uco03URW7/gIqi3PNDv/vuu7zxxhu610lJSQQFBZVPMIoCe74GK0doPKR8jimEMApFSdrV1RVra+uH/uMqHl+KopCTk0NKSgrAQ98abLSJ2t3dHdD+57n1Q6akpNzzvjMLCwssLCx0r8t1NpuT62HzZDCxANcgqNGk/I4thDCYwsJCXZJ2cXExdDiiCrCysgK0OcvV1fWhusGNdq5vf39/3N3d2bJli64sPz+f8PBwWrVq9cjjURSFJekNiTBtBoV5sGIoZF9+5HEIIcpf0TVpa2trA0ciqpKi36eHHfNg0BZ1VlYWZ8+e1b2OjY0lKioKZ2dnfHx8mDhxIjNnziQgIICAgABmzpyJtbU1zz///COPNfeGhoW7zpOWNZJt9hdwzUiEVS/CkLVgYrQdE0KIMpDublGeyuv3yaAt6oMHD9K4cWMaN24MwBtvvEHjxo2ZMmUKAP/5z3+YOHEio0ePJiwsjKSkJDZv3oydnd0jj9XK3ITPB4aQrbJmcOZ4CkysIXYnbJOBa0IIISqOQRN1hw4dUBSlxGPx4sWA9tvI1KlTuXjxIrm5uYSHhxMcHGyweEN9nRjTsTZnFC/eKRylLYz4Eo6vNVhMQghR3jp06MDEiRNLXf/8+fOoVCqioqIqLCaAHTt2oFKpHruR+UZ7jdpYje8cQEMvB1blhvG77QBt4boxkHLSsIEJIR47KpXqno/hw4c/0HHXrFnDRx99VOr63t7eXLx40aANqapMEnUZmZmo+XxgCJZmaiZe7s0F5+ZwIxuWD4bcdEOHJ4R4jFy8eFH3mDdvHvb29nplX3zxhV790g5qcnZ2LtMlRhMTE9zd3e+7rrJ4MJKoH0Ct6rZMfrIehZjwTMpL3LCtAVfPwdpRoNEYOjwhxGPC3d1d93BwcEClUule5+bm4ujoyK+//kqHDh2wtLRkyZIlXLlyheeeew4vLy+sra1p0KABv/zyi95xb+/69vPzY+bMmYwYMQI7Ozt8fHxYuHChbvvtXd9FXdTbtm0jLCwMa2trWrVqRUxMjN77/Pe//8XV1RU7Oztefvll3nnnHUJCQsp0DlavXk39+vWxsLDAz8+POXPm6G3/5ptvCAgIwNLSEjc3N/r166fbtmrVKho0aICVlRUuLi506dKF7OzsMr3/oyCJ+gENaeFLh7rVuVRgy1uqt1BMLCBmA+yac/+dhRBGT1EUcvILDPJQFKXcPsekSZMYP348J0+epHv37uTm5hIaGsoff/zBsWPHGDlyJEOHDmXfvn33PM6cOXMICwvj8OHDjB49mtdee41Tp07dc5/JkyczZ84cDh48iKmpKSNGjNBtW7p0KTNmzGD27NlERkbi4+PDggULyvTZIiMjGTBgAIMGDSI6OpqpU6fywQcf6MY5HTx4kPHjxzN9+nRiYmLYtGkT7dq1A7S9Ec899xwjRozg5MmT7Nixg759+5bruS8v0k/xgFQqFZ8825Du83byW6ob3YLepue//4Xw2RDyHDjI2tdCVGbXbxQSNOUvg7z3iendsTYvnz/PEydO1C1sVOStt97SPR83bhybNm1i5cqVNG/e/K7HefLJJxk9ejSgTf6ff/45O3bsIDAw8K77zJgxg/bt2wPwzjvv0LNnT3Jzc7G0tOSrr77ipZde4sUXXwRgypQpbN68maysrFJ/trlz59K5c2c++OADAOrUqcOJEyf49NNPGT58OPHx8djY2NCrVy/s7Ozw9fXV3WV08eJFCgoK6Nu3L76+vgA0aNCg1O/9KEmL+iG42lsyq29DAMaeDCKpwWgYulaStBDCaISFhem9LiwsZMaMGTRs2BAXFxdsbW3ZvHkz8fHx9zxOw4YNdc+LutiLpsgszT5FM0wW7RMTE0OzZs306t/++n5OnjxJ69at9cpat27NmTNnKCwspGvXrvj6+lKzZk2GDh3K0qVLycnJAaBRo0Z07tyZBg0a0L9/f77//nvS0tLK9P6PirSoH1KPYHf6h3qxMjKRAWe6srFnC+wNHZQQ4qFZmZlwYnp3g713ebGxsdF7PWfOHD7//HPmzZtHgwYNsLGxYeLEieTn59/zOGZmZnqvVSoVmvuMybl1n6LJP27d505rOZTFndZ+uPUYdnZ2HDp0iB07drB582amTJnC1KlTOXDgAI6OjmzZsoWIiAg2b97MV199xeTJk9m3bx/+/v5liqOiSYu6HHz4VH28na1IunadqeuPawtTY2DrNO1CHkKISkelUmFtbmqQR0XOkLZr1y6efvpphgwZQqNGjahZsyZnzpypsPe7m7p167J//369soMHD5bpGEFBQezevVuvLCIigjp16ujm1jY1NaVLly588sknHD16lPPnz/P3338D2n/j1q1bM23aNA4fPoy5uTlr1xrfvBjSoi4HthamfD4ghAHf7WHNoSR61Lam2+ZukHtN2w3e9CVDhyiEEADUrl2b1atXExERgZOTE3PnziU5OZl69eo90jjGjRvHK6+8QlhYGK1atWLFihUcPXqUmjVrlvoYb775Jk2bNuWjjz5i4MCB7Nmzh/nz5/PNN98A8Mcff/Dvv//Srl07nJyc2LBhAxqNhrp167Jv3z62bdtGt27dcHV1Zd++faSmpj7y81Aa0qIuJ2F+zrzWoRYA//njPBkt3gK/tlDvKQNHJoQQxT744AOaNGlC9+7d6dChA+7u7vTp0+eRxzF48GDeffdd3nrrLZo0aUJsbCzDhw/H0tKy1Mdo0qQJv/76K8uXLyc4OJgpU6Ywffp03UQvjo6OrFmzhk6dOlGvXj2+/fZbfvnlF+rXr4+9vT07d+7kySefpE6dOrz//vvMmTOHJ554ooI+8YNTKcY4Fr0cJSYm4u3tTUJCAl5eFTvIK79AQ98F/3AsKYO2tV34aXgoalOz++8ohDCo3NxcYmNj8ff3L1OiEOWra9euuLu78/PPPxs6lHJxr9+rsuQmaVGXI3NTNfMGhmBhqmbX2Sv8b19i8caYjVCQZ7jghBDCiOTk5DB37lyOHz/OqVOn+PDDD9m6dSvDhg0zdGhGRxJ1Oavtasd7T2qvcczaeIozlzJh23T4ZRBsesfA0QkhhHFQqVRs2LCBtm3bEhoayu+//87q1avp0qWLoUMzOjKYrAK80NKXbadS2Hk6lYkroljXrTlmqODgj+DZBJoMNXSIQghhUFZWVmzdutXQYVQK0qKuACqVik/7NcTR2ozjFzL4/LwvdJys3fjnm5AUadgAhRBCVBqSqCuIm70ls57RTkf3bfg5Dvi8CHWfhMI8WPECZF82cIRCCCEqA0nUFeiJBh4828QLjQKv/3qUzCfmg3MtyEiEVS9CYYGhQxRCCGHkJFFXsKlPBeHlZEVi2nWmbUmEQUvBzAZid8K2aYYOTwghhJGTRF3B7CzNmDsgBJUKVkUmsinFEfpoZ80h4ks4tsag8QkhhDBukqgfgWb+zoxqr5217N010aR494DWE7QbfxsLl04YMDohhBDGTBL1I/J6lzrU97QnLecGb686itLpA/BvDzeyYcUQuH7N0CEKIR5THTp0YOLEibrXfn5+zJs37577qFQq1q1b99DvXV7HuZepU6cSEhJSoe9RkSRRPyK3zloWfjqVn/cnQb8fwcEbrp6Dda/JSltCiDLp3bv3XScI2bNnDyqVikOHDpX5uAcOHGDkyJEPG56euyXLixcvGuX82sZEEvUjFOBmxztPBAIw48+TnM22hAH/A+tqEPI8VODSdkKIquell17i77//Ji4ursS2H3/8kZCQEJo0aVLm41avXh1ra+vyCPG+3N3dsbCweCTvVVlJon7EhrX0o21ANfIKNLy+Iop8txCYeBTq9TZ0aEKISqZXr164urqyePFivfKcnBxWrFjBSy+9xJUrV3juuefw8vLC2tqaBg0a8Msvv9zzuLd3fZ85c4Z27dphaWlJUFAQW7ZsKbHPpEmTqFOnDtbW1tSsWZMPPviAGzduALB48WKmTZvGkSNHUKlUqFQqXcy3d31HR0fTqVMnrKyscHFxYeTIkWRlZem2Dx8+nD59+vDZZ5/h4eGBi4sLY8aM0b1XaWg0GqZPn46XlxcWFhaEhISwadMm3fb8/HzGjh2Lh4cHlpaW+Pn5MWvWLN32qVOn4uPjg4WFBZ6enowfP77U7/0gZArRR0ytVvFpv0Z0n7eT6KR0vtx2hre61y2ucPksJO7XtrCFEIaXn132fUwswOTmn9fCAu1ERyo1mFnd/7jmNqV+G1NTU1544QUWL17MlClTUN3slVu5ciX5+fkMHjyYnJwcQkNDmTRpEvb29vz5558MHTqUmjVr0rx58/u+h0ajoW/fvlSrVo29e/eSkZGhdz27iJ2dHYsXL8bT05Po6GheeeUV7Ozs+M9//sPAgQM5duwYmzZt0k0b6uDgUOIYOTk59OjRgxYtWnDgwAFSUlJ4+eWXGTt2rN6Xke3bt+Ph4cH27ds5e/YsAwcOJCQkhFdeeaVU5+2LL75gzpw5fPfddzRu3Jgff/yRp556iuPHjxMQEMCXX37J+vXr+fXXX/Hx8SEhIYGEhAQAVq1axeeff87y5cupX78+ycnJHDlypFTv+6CMOlEXFBQwdepUli5dSnJyMh4eHgwfPpz3338ftbrydga4O1gy85kGjFl2iG92nKVjYHVCfZ0h8xIsfhKyLoGpJQT3NXSoQoiZnmXfp/9iqP+M9vmp32HlcPBtAy/+WVxnXgPIuVJy36npZXqrESNG8Omnn7Jjxw46duwIaLu9+/bti5OTE05OTrz11lu6+uPGjWPTpk2sXLmyVIl669atnDx5kvPnz+uWY5w5c2aJ68rvv/++7rmfnx9vvvkmK1as4D//+Q9WVlbY2tpiamqKu7v7Xd9r6dKlXL9+nf/973/Y2Gi/sMyfP5/evXsze/Zs3NzcAHBycmL+/PmYmJgQGBhIz5492bZtW6kT9WeffcakSZMYNGgQALNnz2b79u3MmzePr7/+mvj4eAICAmjTpg0qlQpfX1/dvvHx8bi7u9OlSxfMzMzw8fGhWbNmpXrfB2XU2W727Nl8++23zJ8/n5MnT/LJJ5/w6aef8tVXXxk6tIfWs6EHfRvX0M5atuIIWXkFYOsKwc+CWzD4tzN0iEKISiAwMJBWrVrx448/AnDu3Dl27drFiBEjACgsLGTGjBk0bNgQFxcXbG1t2bx5M/Hx8aU6/smTJ/Hx8dFbM7lly5Yl6q1atYo2bdrg7u6Ora0tH3zwQanf49b3atSokS5JA7Ru3RqNRkNMTIyurH79+piYmOhee3h4kJKSUqr3yMjI4MKFC7Ru3VqvvHXr1pw8eRLQdq9HRUVRt25dxo8fz+bNm3X1+vfvz/Xr16lZsyavvPIKa9eupaCgYmeZNOoW9Z49e3j66afp2bMnoP2W9ssvv3Dw4EEDR1Y+pj5dn32xV4m/msP034/zSb9G0H0m5GeBhZ2hwxNCALx3oez7mNwyOCqwt/YYqtvaRROjHy6uW7z00kuMHTuWr7/+mkWLFuHr60vnzp0BmDNnDp9//jnz5s2jQYMG2NjYMHHiRPLz80t1bOUOd6Oobhv4unfvXgYNGsS0adPo3r07Dg4OLF++nDlz5pTpcyiKUuLYd3pPMzOzEts0Gk2Z3uv297n1vZs0aUJsbCwbN25k69atDBgwgC5durBq1Sq8vb2JiYlhy5YtbN26ldGjR/Ppp58SHh5eIq7yYtQt6jZt2rBt2zZOnz4NwJEjR9i9ezdPPvnkXffJy8sjIyND98jMzHxU4ZaZvaUZcwc0QqWCXw8m8tfxZO3I71uTdORPcHydwWIU4rFnblP2h8ktbSATU23Zrden73XcBzBgwABMTExYtmwZP/30Ey+++KIu6ezatYunn36aIUOG0KhRI2rWrMmZM2dKfeygoCDi4+O5cKH4C8uePXv06vzzzz/4+voyefJkwsLCCAgIKDES3dzcnMLCwvu+V1RUFNnZxdfv//nnH9RqNXXq1Cl1zPdib2+Pp6cnu3fv1iuPiIigXr16evUGDhzI999/z4oVK1i9ejVXr14FtEt0PvXUU3z55Zfs2LGDPXv2EB1dfl+8bmfULepJkyaRnp5OYGAgJiYmui6c55577q77zJo1i2nTKs8c2s1rujCyXU2+C/+XN389gsuL5oT5OWs3/hsOv48HtSmYmEFgT8MGK4QwSra2tgwcOJD33nuP9PR0hg8frttWu3ZtVq9eTUREBE5OTsydO5fk5GS9pHQvXbp0oW7durzwwgvMmTOHjIwMJk+erFendu3axMfHs3z5cpo2bcqff/7J2rVr9er4+fkRGxtLVFQUXl5e2NnZlbgta/DgwXz44YcMGzaMqVOnkpqayrhx4xg6dKju+nR5ePvtt/nwww+pVasWISEhLFq0iKioKJYuXQrA559/joeHByEhIajValauXIm7uzuOjo4sXryYwsJCmjdvjrW1NT///DNWVlZ617HLm1G3qFesWMGSJUtYtmwZhw4d4qeffuKzzz7jp59+uus+7777Lunp6brHiRPGPz3nm13r0rKmC1l5Bbzw4372/XtzgIlfG2jQHzQF8OswOL353gcSQjy2XnrpJdLS0ujSpQs+Pj668g8++IAmTZrQvXt3OnTogLu7O3369Cn1cdVqNWvXriUvL49mzZrx8ssvM2PGDL06Tz/9NK+//jpjx44lJCSEiIgIPvjgA706zz77LD169KBjx45Ur179jreIWVtb89dff3H16lWaNm1Kv3796Ny5M/Pnzy/bybiP8ePH8+abb/Lmm2/SoEEDNm3axPr16wkICAC0X3xmz55NWFgYTZs25fz582zYsAG1Wo2joyPff/89rVu3pmHDhmzbto3ff/8dFxeXco3xVirlThcgjIS3tzfvvPMOY8aM0ZX997//ZcmSJZw6dapUx0hMTMTb25uEhAS9wRDG5np+Ia/87yC7z17GysyEH4aF0ap2Ne2tHatfghPrtNe9nvsFanc2dLhCVCm5ubnExsbi7++PpaWlocMRVcS9fq/KkpuMukWdk5NT4jYsExOTMg8aqAyszE34v2FhtK9Tnes3Cnlx8QF2nk7VXt969v8gsJf2Xszlz2u7xIUQQjwWjDpR9+7dmxkzZvDnn39y/vx51q5dy9y5c3nmmWcMHVqFsDQz4buhoXQKdCWvQMPL/zvI9lMp2uvT/RZBnR5QkAu/DIK4CEOHK4QQ4hEw6kT91Vdf0a9fP0aPHk29evV46623ePXVV/noo48MHVqFsTQz4dshoXQLciO/QMOrP0ey9cQlMDXXzgteuwvcyIGl/SFhv6HDFUIIUcGMOlHb2dkxb9484uLiuH79OufOneO///0v5ubmhg6tQpmbqvl6cBOebOBOfqGGUUsi2XQsGUwtYOAS7fKY+Vmw5FlIijR0uEIIISqQUSfqx5mZiZovBzWmdyNPCjQKY5Yd4o+jF7T3Yj63XDsdYV4G/PwMXIgydLhCCCEqiCRqI2ZqoubzAY3o27gGhRqF8b8c5reoJDC3hudXgHcLyE2Hn/tAVqqhwxWi0quKA1WF4ZTX75NRT3gitMn60/6NMFGrWBmZyOsroigoVHg21AsGr9S2qAN7gm11Q4cqRKVlbm6OWq3mwoULVK9eHXNz87tOZSnE/SiKQn5+PqmpqajV6oe+XCuJuhIwUauY/WxDTE3U/LI/nrdWHaFQozCgqTe8uFE70EwI8cDUajX+/v5cvHhRb6pMIR6GtbU1Pj4+D73aoyTqSkKtVjGjTzBmJir+tyeO/6w+yg2NhsHNb5m2LjcD1o+DzlPApZbhghWiEjI3N8fHx4eCgoL7zkktxP2YmJhgampaLj0zkqgrEbVaxbSn6mOqVvPjP7FMXnuMgkKFYa38tBU2vaOdwezyGRi1Gyrxmt1CGIJKpcLMzKzCVkES4kFIoq5kVCoVH/Sqh5mJiu92/suH649zo1DDy21rQpepcOUcPDFbkrQQQlQRkqgrIZVKxTtPBGJqouLr7ef4758nKdAojGpfC0Zs0i6VWURR9F8LIYSoVKTZVUmpVCre6laXiV20q718vPEUX207o5+UEw7A/3WGzEsGilIIIcTDkkRdialUKiZ2qcNb3bQLqs/ZcprPt5xGURTQaOD3CdqZy37qDckVt6i5EEKIiiOJugoY2ymAd54IBOCLbWf4bHMMikoFg5aCnSdcjoFv28C3bWHfd5Bz1cARCyGEKC1J1FXEqPa1eL9nPQC+3n6OjzeeQnHygxc3QNDToDaD5KOw8T/wWR1YMRRO/6Vd71oIIYTRksFkVcjLbWtiZqLmw/XH+W7nv+QXapjSKwjVgP9pW9HRKyFqKVw8AifXax+2btBwIDQeAtXrGvojCCGEuI20qKuYYa38mPFMMACL/jnPh+uPo9EoYO0MzV+FV3fCqH+gxWiwdoGsSxDxJXzdDNaMNHD0QgghbieJugoa3NyXT55tiEoF/9sTx+R1x7TJuoh7MPSYBW+cgoFLoe6ToDIBt+DiOvk5cHYraGSGJiGEMCTp+q6iBjT1xkSt4u1VR/hlfzxHE6/xepc6dK7nWjylnak51OulfWSlgMktc4afXA9rXwXf1trr3EIIIQxCWtRV2LOhXnwxqDE25iYcv5DBy/87SJ+v/2FHTIr2Fq5b2bqClWPx67xMsHSEmh2Kywry4NDP2jnFhRBCPBIqpcRf7KolMTERb29vEhIS8PLyMnQ4BnE1O5+FO//lp4jzXL+h7cpu4uPIG13r0rq2y90njS/Ig8J8sLDTvj6+DlYOA1MrCHoKQgaDX1uZrlQIIcqoLLlJEvVj5HJWHt+Fn+N/e+LIK9AuaN7M35k3utahRU2X+x/gxHr4+yO4fLq4zNxOO1DNylHbAi/6aemgfV6tDtTrXVz/WjyY22rrSIIXQjymJFHfQhJ1SSkZuSwIP8fSffHk30zYrWq58EbXOoT5Od97Z0XRznZ2eAkcWwN56feuX6sTDF1b/HqWj3afsQehmnb6Uw78AMfXlkz21i5gUw2sqxU/lwQvhKgCypKbZDDZY8jV3pIPe9fn1Xa1+Hr7WZYfiCfi3BUizu2hbUA13uhah8Y+TnfeWaUCrzDto8fH2hZy7jW4fu3OP6sHFu+r0YCi/WKApWNxeeopOL+rdMGrTLQteL820H9xcfneBdptwc+Czc3egRvXtRO9mMivuRCi8pIWtSDp2nXm/32WlQcTKLh5G1enQFde71KHBl4O5f+GBflgYla8gEhyNKScKpnoc65AzmXtz+wr+q33Wp1h6Jri17O8IS9Dv6W+fSaEz9Z+KbC52Sq3rgbWTtoR7ibmoDYtfm5iCg7e0GhQ8XFP/KaNt3Zn7RcE0H45uZag/QwmZje/DNzcv+hSgNqk/M+bEKLKkBa1KJMajlbM6tuA19rX4qu/z7DmcBJ/n0rh71MpdA1y4/UudQjytC+/NzQ113/t3kD7uJ+C/OLkrb7lV1dRoEE/yL4MNtWLy7Mva3/mXtM+rpy9/3t4NdNP1BsnQeZF7UQxRYn66K/aa/V3pQIrp+JuexsXcK4JXacXV7lwWNsD4FILzG3uH5cQovzlZsCNHG3vW0Hu/X/auEKjgY88TGlRixJiL2fz1bYzrItKomielCcbuDOhcx3qutsZNriy0BTC9TRtwi5K8NmXtWWaAu2I9sIb2ofmhva1kx+0fbP4GKtGaPd56kvtNtBeU9/3rf7+Rc9vZN85lur1YMze4tdfN9d2+b/wW/EtcMfXwp6vi5N7UQ9AUcK3sNMmdQtb7YA8c1sws5L1xoVx0mi0vWDZV27+/7v1cfP/oaJopy/2baXdJzka/vkSnHyh0/vFx9rwH8hO0dZHufkT/edF20D7/7vxEO06BwAXomD589opk0duLz7ut23KtrKgVzN4eUvZz8UdSItaPBT/ajbMHRjC6I61+WLbGf44eoEN0clsPJZMr4aeTOgcQG1XW0OHeX9qE22Ss6n24Mfo92PJsqYvaR93UlgA16/e/HJwufhLgpm1fj3ratpv57f2AFw5B4kHyhafow9MvOUPzbrR2q75LlO14whA23qP2ahN8kUJ3sL25uubyf/Wh4m5JH+hrygZFv1eXEuAuAjt3R11exTX+9/TkJl8MxlfBaUUMxv6tCxO1JnJEP0reDTST9SnN8G1uLLF7NNC/3VGUvEYmSKmVoBK+4XX1PIePy21dYsuqz1iRp+ok5KSmDRpEhs3buT69evUqVOHH374gdDQUEOHVuXVdrXlq+caM7Zjbb7YdpoN0cn8fuQCfx69QJ+QGozvHIBfNem21WNiqp08xtb13vVe/LNkWXBf7cIouiR/RT/Z52dBfjbkZRW33G//ApAUqW2p38jRLwufXfrPoDIBe094/Vhx2V+TITUG2rwOfq21Zakx2hnszGxKJvuiMlOLm9fvb17PNzE3nq5+jaa4J+XWnpWCvJuPXO2jRqj2cwAkHtSuQucWDN7NtGXZl2Hnpze7R/Og4OZP3evc4oeiFCe7gUu10/kCRC6GiK+0tzJ2maoty8+B7zveDFZ1y5en25/f9rme+BR8W2qfn/wDdszSJsInPy2u81177efW61C95fmtLdb8bO3vX9/vtfMngPYL5dqR2pkLb03UKSe16wfcysJee9nI+pZeImtn7eUhtSl4Ni6uW60OdJtR8v9Ph3e0kzDd+tlLnI9bfqpNSh73le3aL6m3enGDNgYj/2Jq1Ik6LS2N1q1b07FjRzZu3Iirqyvnzp3D0dHR0KE9Vuq62/HN4FBOXMhg3tbTbD5xiTWHk/jtyAWeaVyDUe1rVY4WtrFzrql9lIZGo03WBfn65U9+Ctmp2q72ItUDoenL2gSfn1Wc8IuSfn6WNrEX5GrrK4Ul53hPPAAJ+yB0eHFZcjT8/d+yfUaVGj5MK369agSc2QpPfAwhz2vLEvbD7xNuGeh3S5JXFw3gM72ZZAuKk+3zK7UtH4BtH2kHArYaWxzzhcOwuHdx/dtbV3czMVrbcwE3L0/Mh1bjixN1frb2UkhZFd7yb3c9TTuGIiuluEzRaL90lVV+VvHz3Gtw6RjY19Cvk3qq+N+7tHKuFD938tVesrl9bMnT32j/fYpup7RyLjkm5V6cfLX/Zrcr+t14UObWUKNJyXITs4c77iNi1Il69uzZeHt7s2jRIl2Zn5+f4QJ6zAV52rPwhTCiE9P5fOtp/j6VwqrIRFYfSqR7kDujOtQixNvR0GE+HtRq7TVri9vK/duVrOvXRvu4n8ICbfLPz9ZPIgDtbw6q82hUXOboA01euJn0c4q/ANzIuVmWpf0iUZQYQX8+edB+UchL10+auemQcuL+8ZaIP784UWddgitnigcUgvZLQn7mvY9RNIK/qKvT1EK/1ekWDIG99G87tHLSjmsoqq/rKr31cbNcpUbXcq1Wp/gYDQaAd3Pt5ZAiZlYw7A+Kr8Pedi1W7zotxS1rj5DiYxTNY2B924RGg1eW7M7Wvrjl6c3nZtba/W3dirfVCNWOr7hdQJeSZeKhGfVgsqCgILp3705iYiLh4eHUqFGD0aNH88orr9x1n7y8PPLy8nSvk5KSCAoKksFkFSAq4RrfbD/L5hPFXV2tarnwWodatKld7e5Tk4rHj6LcHMB3Q9u6KZJ5SdulaVOteK75nKva1vqtg/xuHbRX1JI2Mb3l1jgzbbdxURd16mnt4CMnP3C4+f/+Rq72OuXtt9Td2kqX31nxiFSZmcksLbXfjt944w369+/P/v37mThxIt999x0vvPDCHfeZOnUq06ZNK1EuibrinLmUyXc7/2Xd4STdfdjBNex5rX1tegS7Y6KWP35CCHGrKpOozc3NCQsLIyIiQlc2fvx4Dhw4wJ49e+64j7SoDSfp2nV+2BXLL/vjdYt/+LlYM7JdLfo2qYGlmUwCIoQQULZEbdSTJnt4eBAUFKRXVq9ePeLj4++6j4WFBfb29rqHnV0luu+3kqvhaMWU3kFEvNOJCZ0DcLQ24/yVHN5bG03bT7bzbfg5MnNvGDpMIYSoVB4oUSckJJCYmKh7XdQlvXDhwnILDKB169bExMTolZ0+fRpfX99yfR9RvpxszHm9ax3+mdSJKb2C8HCwJDUzj483nqLVx3/zyaZTpGbm3f9AQgghHixRP//882zfrp3dJTk5ma5du7J//37ee+89pk+ffp+9S+/1119n7969zJw5k7Nnz7Js2TIWLlzImDFjyu09RMWxsTBlRBt/wt/uyGf9G1Hb1ZbM3AK+2XGO1rP/5v110cRfybn/gYQQ4jH2QIn62LFjNGumvYfw119/JTg4mIiICJYtW8bixYvLLbimTZuydu1afvnlF4KDg/noo4+YN28egwcPLrf3EBXP3FRNv1AvNk9sx8KhoYR4O5JfoGHJ3ng6fLad8b8c5sSFDEOHKYQQRumB7qO+ceMGFhba2yC2bt3KU09pZ6sJDAzk4sWL5Rcd0KtXL3r16lWuxxSGoVar6Fbfna5BbuyLvcqCHecIP53K+iMXWH/kAh3qVue19rVo5u8st3YJIcRND9Sirl+/Pt9++y27du1iy5Yt9OihnULuwoULuLi43Gdv8bhTqVS0qOnCTyOa8ce4NvRu5IlaBTtiUhm4cC/PLohgy4lLFGqM9oYEIYR4ZB7o9qwdO3bwzDPPkJGRwbBhw/jxR+3CBe+99x6nTp1izZo19znCoyOrZ1UOcVeyWbjzX1ZGJpJfoJ2lytxUTc1qNtRytaV2dVvdz5rVbeRWLyFEpfZI7qMuLCwkIyMDJycnXdn58+extrbG1fU+CxI8QpKoK5eUzFwW/XOeJXvjyMwtuGMdlQq8nayp7WpLbVdbalW30T6vboeDdeWYu1cI8Xir8ER9/fp1FEXB2lo7FWBcXBxr166lXr16dO/e/cGiriCSqCunQo1CUtp1zqZmcjYlS++RcZcEDlDN1oLarkWJ+2Yr3NUWd3tLue4thDAaFb4e9dNPP03fvn0ZNWoU165do3nz5piZmXH58mXmzp3La6+99kCBC1HERK3Cx8UaHxdrOgUWLwagKAqXs/K1STs1i3M3k/e51CwupudyOSuPy1l57P33qt7xbC1MqVVd241ez92epxt74mpn+ag/lhBClNkDJepDhw7x+eefA7Bq1Src3Nw4fPgwq1evZsqUKZKoRYVRqVRUt7Ogup0FLWvpD1zMyivQJe6zqcUJPO5KDll5BRxJTOdIYjqQxKd/xfB0iCcvt61JXXeZvU4IYbweKFHn5OTopubcvHkzffv2Ra1W06JFC+Li4so1QCFKy9bClEbejjS6banN/AINcVeydV3n22NSOBR/jZWRiayMTKRtQDVeaVuTtgGy4pcQwvg8UKKuXbs269at45lnnuGvv/7i9ddfByAlJQV7e/tyDVCIh2VuqibAzY4AN+2Xy3GdA4iMS+OH3f+y6Vgyu85cZteZy9R1s+Oltv48HeKJhamMKhdCGIcHuo96ypQpvPXWW/j5+dGsWTNatmwJaFvXjRs3LtcAhagIob5OfDM4lB1vdeTF1n7YmJsQcymT/6w6SuuPt/PVtjOkZecbOkwhhHjw27OSk5O5ePEijRo1Qq3W5vv9+/djb29PYGBguQb5MGTUtyiN9Os3WL4/nsUR57mYnguApZmaZ5t48VIbf2pWtzVwhEKIquSRrkedmJiISqWiRo0aD3OYCiOJWpTFjUING6Iv8v2ufzmWpJ1/XKWCzoGuvNy2Js1lelMhRDmo8PWoNRoN06dPx8HBAV9fX3x8fHB0dOSjjz5Co9E8UNBCGAMzEzVPh9Tg97FtWD6yBV3quaIosPVkCoMW7uWp+f/wW1QSNwrl91wI8Wg80GCyyZMn88MPP/Dxxx/TunVrFEXhn3/+YerUqeTm5jJjxozyjlOIR6poPvIWNV04l5rFj7tjWRWZSHRSOhOWR/HxxlMMb+XHoGY+OFjJbGhCiIrzQF3fnp6efPvtt7pVs4r89ttvjB49mqSkpHIL8GFJ17coL1ez81m6N46f9sRxOSsPABtzEwY09WZEa3+8na0NHKEQorKo8K7vq1ev3nHAWGBgIFevXr3DHkJUfs425ozrHMDuSR35pF9D6rrZkZ1fyKJ/ztP+0+2MXhrJrjOp5OTffYpTIYQoqwfq+m7UqBHz58/nyy+/1CufP38+DRs2LJfAhDBWlmYmDAjzpn+oFzvPXOb/dv3LrjOX2RCdzIboZEzVKoJrONDM35mmfs409XPC0drc0GELISqpB+r6Dg8Pp2fPnvj4+NCyZUtUKhUREREkJCSwYcMG2rZtWxGxPhDp+haPwqnkDH6KOE94TCoXbt7edas6brY09XOmmb/24eFgZYAohRDG4pHcnnXhwgW+/vprTp06haIoBAUFMXLkSKZOnapbn9oYSKIWj1piWg77Y69y4PxV9sde5Vxqdok6Xk5WNPNzpunNxF2zmo3c9iXEY+SR3kd9qyNHjtCkSRMKCwvL65APTRK1MLTLWXkcPH+V/bFpHDh/leMX0tHc9r+umq05Yb43E7efM/U87DA1eaAhJEKISqDCl7kUQpReNVsLegR70CPYA9Cu8nUoLo39sVfZf/4qUQnXuJyVz6bjyWw6ngxoFxhp4utEMz8nmvo508jbEUszmX9ciMeRJGohHjFbC1Pa1alOuzrVAcgrKCQ6MZ39N7vKI8+nkZlXwM7Tqew8nQpoFxZ5upEnYzvVxtfFxpDhCyEeMUnUQhiYhakJYX7OhPk5M7oDFGoUTiVncCD2KgfOp7Ev9iqXs/JYGZnImsNJ9G1cQxK2EI+RMiXqvn373nP7tWvXHiYWIQRgolZR39OB+p4ODG/tj6IoHIq/xpfbzhB+OlUSthCPmTIlagcHh/tuf+GFFx4qICGEPpVKRaivEz+NaMah+DS+2CoJW4jHSbmO+jZGMupbVEW3JmzQtsIlYQtReVT4FKKGMmvWLFQqFRMnTjR0KEIYVBMfbQt77ehWdKhbnUKNwsrIRDrNCeftlUeIu1Ly3m0hROVUaRL1gQMHWLhwoUxRKsQtGvs4sfhFSdhCVGWVIlFnZWUxePBgvv/+e5ycnAwdjhBG514J+62VRzh/WRK2EJVVpUjUY8aMoWfPnnTp0uW+dfPy8sjIyNA9MjMzH0GEQhiHOyXsVZGJdJ4rCVuIysroE/Xy5cs5dOgQs2bNKlX9WbNm4eDgoHsEBQVVcIRCGB9J2EJUHUadqBMSEpgwYQJLlizB0tKyVPu8++67pKen6x4nTpyo4CiFMF6SsIWo/Iz69qx169bxzDPPYGJSPMdxYWEhKpUKtVpNXl6e3rY7kduzhCh2OD6NL7adYUdM8W1dTzfyZHALH5r4OMkKXkI8IgZbPau8ZWZmEhcXp1f24osvEhgYyKRJkwgODr7vMSRRC1HS7QkboGZ1GwaEedO3SQ1c7UrXgyWEeDBVZvUsOzu7EsnYxsYGFxeXUiVpIcSdFXWJRyVc4+c9cWyIvsi/qdl8vPEUn/4VQ8e61ekf5k2nQFfMZLlNIQzKqBO1EKJihXg7EuLtyNSngvjz6EV+PZjAofhrbD2ZwtaTKVSzNeeZxjXoH+ZNHTc7Q4crxGPJqLu+y4N0fQtRNmdTMll5MJHVh5K4nJWnKw/xdmRAmDe9Gnlgb2lmwAiFqPyqzDXq8iCJWogHc6NQQ3hMKr8eTODvUykUaLR/KizN1DwZ7EH/MG+a+zujVssANCHKqspcoxZCGI6ZiZouQW50CXIjNTOPdYeTWHEwgbMpWaw5nMSaw0n4OFvTL9SLZ0O9qOFoZeiQhaiSpEUthCg1RVGISrjGrwcT+f3IBbLyCgBQqaBN7WoMCPOma5Ablmb3vm1SiMedtKiFEBVCpVLR2MeJxj5OTOkVxMZjF1l5MJE9/15h15nL7DpzGQcrM/qEeNI/zJvgGvdew14IcX/SohZCPLT4KzmsikxgVWQiF9JzdeX1Pe0Z1NSbp0Jq4GAlA9CEKCKDyW4hiVqIR6dQo/DP2cv8ejCBzccvkV+oAcDCVM2TDTwY2FQ7AE1mQBOPO+n6FkIYhIlaRbs61WlXpzpp2fmsi0pixYEETiVnsvZwEmsPJ+FfTTsD2rOhMgOaEKUhLWohRIVSFIWjieksP5DA+qgksvMLAW1S7xzoyqBm3rQLqI6pzIAmHiPSohZCGA2VSkUjb0caeTvyfs96/Bl9kRUHEoiMS2PziUtsPnEJN3sL+od6MyDMGx8Xa0OHLIRRkRa1EMIgzlzKZMWBBNYcTuJqdr6uvHVtFwY29aGb3OYlqjAZTHYLSdRCGLe8gkK2nkhh+YF4dp+9TNFfJEdrM55pXIOBTb0JdLc3bJBClDPp+hZCVBoWpib0bOhBz4YeJKblsPJgIisPJnAhPZdF/5xn0T/naeTtyKCm3vRu5ImthfzZEo8XaVELIYxOoUZh15lUVhxIYMuJS7p5xq3NTejV0IOBTX1o4uMot3mJSkta1EKISs1EraJDXVc61HXlclYeaw4lsvxAAv+mZvPrwUR+PZhIoLsdg5v70KdxDexkNS9RhUmLWghRKSiKwsG4NFYcSOCPoxfIvaGdTMXa3ISnQ2owpIUP9T1lylJROchgsltIohai6knPucGaw4ks2RvHudRsXXljH0cGN/elV0MPGTEujJok6ltIohai6lIUhX2xV1myN46/jidzo1D758zByox+oV4Mbu5Dzeq2Bo5SiJLkGrUQ4rGgUqloUdOFFjVdSM3M49eDCSzbF0/Stev8sDuWH3bH0rq2C0Oa+9IlyA0zmf1MVEKSqIUQVUJ1OwvGdKzNqPa1CD+dwtK98fwdk8I/Z6/wz9kruNpZMKipN4Oa+eDpaGXocIUoNUnUQogqxUStolOgG50C3UhMy2H5/gSWH0ggJTOPL/8+y/ztZ+kU6MaQFj60C6iOWi23eAnjJteohRBVXn6Bhs0nklm6N549/17RlXs7W/F8M1/6h3lRzdbCgBGKx40MJruFJGohxK3OpmSxdF8cqyMTycgtAMDMRMUTwR4MaeFLUz8nmUhFVDhJ1LeQRC2EuJPr+YX8fvQCS/fFcyThmq7cy8mKJj5O2hW/vByo7+mAlbnc6iXKl4z6FkKI+7AyN2FAmHZpzejEdJbui+O3qAskpl0nMe06649cALTXvOu42RHi7UAjL0caejlSx81W1s8Wj4y0qIUQ4qbM3Bscjr/G0cRrRCWkcyTxGqmZeSXqWZqpCfZ0oJG3Iw29HAjxdsTH2Vq6zEWpVZkW9axZs1izZg2nTp3CysqKVq1aMXv2bOrWrWvo0IQQVZCdpRnt6lSnXZ3qgHZCleSMXI4kXONIYjpHEq5xNDGdrLwCDsalcTAuTbevo7UZDb0cCfFyoKGXI428HaluJwPUxMMz6kQdHh7OmDFjaNq0KQUFBUyePJlu3bpx4sQJbGxsDB2eEKKKU6lUeDhY4eFgRY9gDwA0GoV/L2ffTN7aBH7yQgbXcm6w83QqO0+n6vb3dLDUXuv2dqSRlyOhvk6Ym0qXuSibStX1nZqaiqurK+Hh4bRr165U+0jXtxCiouUVFBKTnMmRBG2X+dHEa5xNzeL2v66udhYMa+XH4OY+OFqbGyZYYRSqTNf37dLT0wFwdna+a528vDzy8oqvKWVmZlZ4XEKIx5uFqQkNbw40G9pSW5aZe4PopHSO3uwyP3D+KimZeXz6Vwzz/z5L/zAvRrT2x6+a9A6Ke6s0LWpFUXj66adJS0tj165dd603depUpk2bVqJcWtRCCEPKL9Dwx9ELfL8rlpMXMwBQqaBrPTdebltT7t9+zFTJ+6jHjBnDn3/+ye7du+/5oW5vUSclJREUFCSJWghhFBRFYc+5K3y/61+2xxRfz27o5cDLbWvyZLC73Pr1GKhyiXrcuHGsW7eOnTt34u/vX6Z95Rq1EMJYnU3J5Ifdsaw+lER+gQaAGo5WDG/lx8Bm3thbmhk4QlFRqkyiVhSFcePGsXbtWnbs2EFAQECZjyGJWghh7C5n5bFkbxw/74njSnY+ALYWpgxs6s2Lrf3wcrI2cISivFWZRD169GiWLVvGb7/9pnfvtIODA1ZWpVumThK1EKKyyL1RyLrDSfzf7ljOpmQB2pnRegS780rbmoR4Oxo2QFFuqkyivtvAikWLFjF8+PBSHUMStRCistFoFMLPpPLDrlh2n72sK2/q58RLbWrSNcgNE1mes1KrMrdnGfF3CCGEqDBqtYqOdV3pWNeVExcy+GF3LOuPJHHgfBoHzkfi62LNiNb+9A/zwtrcqP+Mi3Jg1C3q8iAtaiFEVXApI5efIs6zdF886ddvAOBgZcbzzX0Y3soPN3tLA0coyqLKdH2XB0nUQoiqJCe/gNWRifywO5bzV3J05f7VbAiu4UCwpz0NajhQv4YDDlYyatxYVZmubyGEEPqszU0Z2tKP55v7su3kJf5vVyz7z18l9nI2sZez+f3m8pwAvi7WBHs6EFzDgQY1HAiuYS9Tl1ZCkqiFEKISMlGr6FbfnW713bmanc+xpHSik9I5lpTOsQvpJFy9TtyVHOKu5PBn9EXdfl5OVjeTtoPup7ONJG9jJolaCCEqOWcbc73lOQGu5eRzLClDm7wvaBN43JUcEtOuk5h2nY3HknV1azhaEVzDXtv69tIm8Gq2skSnsZBELYQQVZCjtTltAqrRJqCariz9+g2O30za0UkZHEtKJ/ZyNknXrpN07Tp/Hb+kq+vhYEl9TwcaeTkQ4qNdqlNmSjMMSdRCCPGYcLAyo1WtarSqVZy8M3NvcPxChl7X+b+Xs7mYnsvF9Fy2ntQmb5UKalW3pbG3IyE+jjT2dqKOm63MS/4ISKIWQojHmJ2lGS1qutCipouuLCuvgBMXtN3m2jW2rxF/NYezKVmcTcliZWQiAFZmJjS82eJu7O1IYx8nuU2sAkiiFkIIocfWwpRm/s4083fWlV3OyuNIwjUOx2sT95GEa2TmFbAv9ir7Yq/q6nk4WNLYx5GQm4k72NMBK3MTQ3yMKkMStRBCiPuqZmtB53pudK7nBminOT2XmsXh+GscTrjG4fg0Tl/K1HaZRyezIVo7WM1EraKehx0h3o6EeDvR2McRfxcb1DIFaqlJohZCCFFmarWKADc7AtzsGNDUG4DsvAKik9JvtrrTOBx/jZTMPI4lZXAsKYMle+MBsLc0JcTHiSY+jjTxcSLERwaq3YskaiGEEOXCxsJU73q3oihcTM/VS9zRSelk5Baw83QqO0+nAtqBanVc7Wjiq+0uD/V1omY1m7suzPS4kUQthBCiQqhUKjwdrfB0tKJnQw8AbhRqOHUxk8MJaRyKS+NQvHagWsylTGIuZfLL/gQAHK3NaHJLq7uRtyM2Fo9nyno8P7UQQgiDMDNR08DLgQZeDrzQ0g+AlExtq1ubuNM4mpjOtZwb/H0qhb9PpQCgVkGguz1NfB0J9XWiiY8TPs7Wj0WrWxK1EEIIg3K1s6R7fXe613cHIL9Aw4mLGbrEfSgujQvpuZy4mMGJi8XXuqvZmtPYx0nX8m7o5VglR5hLohZCCGFUzE3VN0eJOzICfwAupl/nUNw1beKOT+NYUjqXs/LZcuISW05oJ2UxVasI8rSnkZcjdd3tqONmRx0320q/EIkkaiGEEEbPw8GKng2Lr3Xn3ijk+IV0DsVdIzIujcj4NFIz8ziamM7RxHS9fV3tLKjjZkeAm+3N5K19XllGmkuiFkIIUelYmpkQ6utMqK8zr6AdYZ6Ydp1D8Wkcv5DB6UuZnLmURdK166Rk5pGSmcfus5f1juHhYEmAmx113WwJKErgrrZGN2jNuKIRQgghHoBKpcLb2RpvZ2ueDqmhK8/MvcGZlCzOXMrk9KUsTl/K5PSlTC5l5OnmMy+6TayIl5OVrtVd92YCr+1qi6WZYa5/S6IWQghRZdlZFt3m5aRXnp5zgzMp+sn79KUsLmfl6ZYCLRpxDtp7vX2crQnxduSLQY0f6WeQRC2EEOKx42BtRpifM2F+znrlV7Pzb3ab6yfxtJwbxF3JwdHq0V/XlkQthBBC3ORsY15iNTFFUbiclc+ZS5lolEcfkyRqIYQQ4h5UKhXV7SyobmdhkPeXFb+FEEIIIyaJWgghhDBikqiFEEIIIyaJWgghhDBikqiFEEIII1blR31rNBoALl68aOBIhBBCCK2inFSUo+6lyifqS5e0q6o0a9bMwJEIIYQQ+i5duoSPj88966gURTHA7duPTkFBAYcPH8bNzQ21+uF6+jMzMwkKCuLEiRPY2dmVU4RVm5yzspNzVnZyzspOzlnZlec502g0XLp0icaNG2Nqeu82c5VP1OUpIyMDBwcH0tPTsbe3N3Q4lYKcs7KTc1Z2cs7KTs5Z2RnqnMlgMiGEEMKISaIWQgghjJgk6jKwsLDgww8/xMLCMPO9VkZyzspOzlnZyTkrOzlnZWeocybXqIUQQggjJi1qIYQQwohJohZCCCGMmCRqIYQQwohJoi6Db775Bn9/fywtLQkNDWXXrl2GDslozZo1i6ZNm2JnZ4erqyt9+vQhJibG0GFVGrNmzUKlUjFx4kRDh2L0kpKSGDJkCC4uLlhbWxMSEkJkZKShwzJKBQUFvP/++/j7+2NlZUXNmjWZPn16qaaxfFzs3LmT3r174+npiUqlYt26dXrbFUVh6tSpeHp6YmVlRYcOHTh+/HiFxiSJupRWrFjBxIkTmTx5MocPH6Zt27Y88cQTxMfHGzo0oxQeHs6YMWPYu3cvW7ZsoaCggG7dupGdnW3o0IzegQMHWLhwIQ0bNjR0KEYvLS2N1q1bY2ZmxsaNGzlx4gRz5szB0dHR0KEZpdmzZ/Ptt98yf/58Tp48ySeffMKnn37KV199ZejQjEZ2djaNGjVi/vz5d9z+ySefMHfuXObPn8+BAwdwd3ena9euZGZmVlxQiiiVZs2aKaNGjdIrCwwMVN555x0DRVS5pKSkKIASHh5u6FCMWmZmphIQEKBs2bJFad++vTJhwgRDh2TUJk2apLRp08bQYVQaPXv2VEaMGKFX1rdvX2XIkCEGisi4AcratWt1rzUajeLu7q58/PHHurLc3FzFwcFB+fbbbyssDmlRl0J+fj6RkZF069ZNr7xbt25EREQYKKrKJT09HQBnZ2cDR2LcxowZQ8+ePenSpYuhQ6kU1q9fT1hYGP3798fV1ZXGjRvz/fffGzoso9WmTRu2bdvG6dOnAThy5Ai7d+/mySefNHBklUNsbCzJycl6ucDCwoL27dtXaC6o8qtnlYfLly9TWFiIm5ubXrmbmxvJyckGiqryUBSFN954gzZt2hAcHGzocIzW8uXLOXToEAcOHDB0KJXGv//+y4IFC3jjjTd477332L9/P+PHj8fCwoIXXnjB0OEZnUmTJpGenk5gYCAmJiYUFhYyY8YMnnvuOUOHVikU/b2/Uy6Ii4ursPeVRF0GKpVK77WiKCXKREljx47l6NGj7N6929ChGK2EhAQmTJjA5s2bsbS0NHQ4lYZGoyEsLIyZM2cC0LhxY44fP86CBQskUd/BihUrWLJkCcuWLaN+/fpERUUxceJEPD09GTZsmKHDqzQedS6QRF0K1apVw8TEpETrOSUlpcQ3K6Fv3LhxrF+/np07d+Ll5WXocIxWZGQkKSkphIaG6soKCwvZuXMn8+fPJy8vDxMTEwNGaJw8PDwICgrSK6tXrx6rV682UETG7e233+add95h0KBBADRo0IC4uDhmzZoliboU3N3dAW3L2sPDQ1de0blArlGXgrm5OaGhoWzZskWvfMuWLbRq1cpAURk3RVEYO3Ysa9as4e+//8bf39/QIRm1zp07Ex0dTVRUlO4RFhbG4MGDiYqKkiR9F61bty5x29/p06fx9fU1UETGLScnB7Va/8++iYmJ3J5VSv7+/ri7u+vlgvz8fMLDwys0F0iLupTeeOMNhg4dSlhYGC1btmThwoXEx8czatQoQ4dmlMaMGcOyZcv47bffsLOz0/VGODg4YGVlZeDojI+dnV2J6/c2Nja4uLjIdf17eP3112nVqhUzZ85kwIAB7N+/n4ULF7Jw4UJDh2aUevfuzYwZM/Dx8aF+/focPnyYuXPnMmLECEOHZjSysrI4e/as7nVsbCxRUVE4Ozvj4+PDxIkTmTlzJgEBAQQEBDBz5kysra15/vnnKy6oChtPXgV9/fXXiq+vr2Jubq40adJEbjW6B+COj0WLFhk6tEpDbs8qnd9//10JDg5WLCwslMDAQGXhwoWGDsloZWRkKBMmTFB8fHwUS0tLpWbNmsrkyZOVvLw8Q4dmNLZv337Hv13Dhg1TFEV7i9aHH36ouLu7KxYWFkq7du2U6OjoCo1JVs8SQgghjJhcoxZCCCGMmCRqIYQQwohJohZCCCGMmCRqIYQQwohJohZCCCGMmCRqIYQQwohJohZCCCGMmCRqIYQQwohJohZClDuVSsW6desMHYYQVYIkaiGqmOHDh6NSqUo8evToYejQhBAPQBblEKIK6tGjB4sWLdIrs7CwMFA0QoiHIS1qIaogCwsL3N3d9R5OTk6Atlt6wYIFPPHEE1hZWeHv78/KlSv19o+OjqZTp05YWVnh4uLCyJEjycrK0qvz448/Ur9+fSwsLPDw8GDs2LF62y9fvswzzzyDtbU1AQEBrF+/XrctLS2NwYMHU716daysrAgICCjxxUIIoSWJWojH0AcffMCzzz7LkSNHGDJkCM899xwnT54EtGsW9+jRAycnJw4cOMDKlSvZunWrXiJesGABY8aMYeTIkURHR7N+/Xpq166t9x7Tpk1jwIABHD16lCeffJLBgwdz9epV3fufOHGCjRs3cvLkSRYsWEC1atUe3QkQojKp0LW5hBCP3LBhwxQTExPFxsZG7zF9+nRFUbRLkI4aNUpvn+bNmyuvvfaaoiiKsnDhQsXJyUnJysrSbf/zzz8VtVqtJCcnK4qiKJ6ensrkyZPvGgOgvP/++7rXWVlZikqlUjZu3KgoiqL07t1befHFF8vnAwtRxck1aiGqoI4dO7JgwQK9MmdnZ93zli1b6m1r2bIlUVFRAJw8eZJGjRphY2Oj2966dWs0Gg0xMTGoVCouXLhA586d7xlDw4YNdc9tbGyws7MjJSUFgNdee41nn32WQ4cO0a1bN/r06UOrVq0e6LMKUdVJohaiCrKxsSnRFX0/KpUKAEVRdM/vVMfKyqpUxzMzMyuxr0ajAeCJJ54gLi6OP//8k61bt9K5c2fGjBnDZ599VqaYhXgcyDVqIR5De/fuLfE6MDAQgKCgIKKiosjOztZt/+eff1Cr1dSpUwc7Ozv8/PzYtm3bQ8VQvXp1hg8fzpIlS5g3bx4LFy58qOMJUVVJi1qIKigvL4/k5GS9MlNTU92ArZUrVxIWFkabNm1YunQp+/fv54cffgBg8ODBfPjhhwwbNoypU6eSmprKuHHjGDp0KG5ubgBMnTqVUaNG4erqyhNPPEFmZib//PMP48aNK1V8U6ZMITQ0lPr165OXl8cff/xBvXr1yvEMCFF1SKIWogratGkTHh4eemV169bl1KlTgHZE9vLlyxk9ejTu7u4sXbqUoKAgAKytrfnrr7+YMGECTZs2xdrammeffZa5c+fqjjVs2DByc3P5/PPPeeutt6hWrRr9+vUrdXzm5ua8++67nD9/HisrK9q2bcvy5cvL4ZMLUfWoFEVRDB2EEOLRUalUrF27lj59+hg6FCFEKcg1aiGEEMKISaIWQgghjJhcoxbiMSNXu4SoXKRFLYQQQhgxSdRCCCGEEZNELYQQQhgxSdRCCCGEEZNELYQQQhgxSdRCCCGEEZNELYQQQhgxSdRCCCGEEZNELYQQQhix/wdRcOUMfHHpogAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425e217f-7854-4544-b224-27cb6611bf1c",
   "metadata": {},
   "source": [
    "- 从上面的结果可以看出，模型开始时生成的是一串无法理解的单词，而到了后期，它能够产生语法上或多或少正确的句子。\n",
    "- 然而，根据训练和验证集的损失，我们可以看到模型开始过拟合。\n",
    "- 如果我们检查它在训练结束时写的几段文字，我们会发现自己的写作完全照搬了训练集——它只是简单地记住了训练数据。\n",
    "- 稍后，我们将介绍可以一定程度上减轻这种记忆的解码策略。\n",
    "- 请注意，这里的过拟合发生是因为我们有一个非常非常小的训练集，并且我们多次迭代它。\n",
    "  - 这里的LLM训练主要是为了教育目的；我们主要想看到模型能够学会产生连贯的文本。\n",
    "  - 我们不是花几周或几个月的时间在大量昂贵的硬件上训练这个模型，而是稍后加载预训练的权重。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcb2eb6-1701-41c2-b7ed-0897d86a94ec",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model-2.webp\" width=350px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03086749-7d71-41af-8c98-1ebd53352580",
   "metadata": {},
   "source": [
    "## 5.3 Decoding strategies to control randomness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71066005-af5e-4b84-9cb3-85935af9a712",
   "metadata": {},
   "source": [
    "- 先将模型从GPU传回CPU，因为相对较小的模型推理不需要GPU。\n",
    "- 使用我们在前一章中使用过的`generate_text_simple`函数（简单训练函数内部），我们可以一次生成一个单词（或标记）的新文本。\n",
    "- 如第5.1.2节所解释的，下一个生成的标记是词汇表中所有标记中概率分数最大的标记对应的标记。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b4828875-b906-483b-8d82-dcc20bb257e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.to(\"cpu\")  # 将模型移至CPU\n",
    "model.eval()  # 设置模型为评估模式\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")  # 获取词元编码器\n",
    "token_ids = generate_text_simple(  # 调用generate_text_simple函数生成词元\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),  # 将文本转换为词元ID\n",
    "    max_new_tokens=25,  # 最大生成词元数为25\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]  # 上下文大小为GPT_CONFIG_124M的context_length\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))  # 打印生成的文本\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596f0e27-3000-4018-9b22-319341cd39d0",
   "metadata": {},
   "source": [
    "- 即使我们多次执行上面的`generate_text_simple`函数，LLM也总是生成相同的输出。\n",
    "- 我们现在引入两个概念，即所谓的解码策略，来修改`generate_text_simple`：*温度缩放*和*top-k*采样。\n",
    "- 这些将允许模型控制生成文本的随机性和多样性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9add1f63-0ee8-4654-b4bd-321490b6c483",
   "metadata": {},
   "source": [
    "### 5.3.1 Temperature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8881fdbf-d70d-4b3e-be6c-c94b492613c7",
   "metadata": {},
   "source": [
    "- 之前，我们总是使用`torch.argmax`采样最高概率的标记作为下一个标记。\n",
    "- 为了增加多样性，我们可以使用`torch.multinomial(probs, num_samples=1)`从概率分布中采样下一个标记。\n",
    "- 在这里，每个索引被选中的机会对应于其在输入张量中的概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6e5ca5-7789-4dd1-91cc-733b3089cb03",
   "metadata": {},
   "source": [
    "- 这是一个关于生成下一个标记的小回顾，假设一个非常小的词汇表用于说明目的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4c33d389-5ea0-4907-9d56-9cc08d4892bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "vocab = {  # 定义词汇表\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}  # 定义反向词汇表\n",
    "\n",
    "next_token_logits = torch.tensor(  # 定义下一个词元的logits\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)  # 将logits转换为概率\n",
    "next_token_id = torch.argmax(probas).item()  # 获取概率最大的词元ID\n",
    "print(inverse_vocab[next_token_id])  # 打印生成的词元\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "986cdb44-a4ba-4d14-90be-9743b45769ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)  # 设置随机种子\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()  # 使用多项式分布采样\n",
    "print(inverse_vocab[next_token_id])  # 打印生成的词元"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3028be-cf07-4f43-ae7a-4a7af410f0f8",
   "metadata": {},
   "source": [
    "- 我们不是通过`torch.argmax`来确定最可能的标记，而是使用`torch.multinomial(probas, num_samples=1)`通过从softmax分布中采样来确定最可能的标记。\n",
    "- 为了说明目的，让我们看看当我们使用原始的softmax概率1,000次采样下一个标记时会发生什么："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ff30f9b9-f5c0-443f-8762-509002e6c41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas): \n",
    "    torch.manual_seed(123)  # 设置随机种子\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]  # 进行1000次采样\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))  # 计算每个词元的出现频率\n",
    "    for i, freq in enumerate(sampled_ids):  # 遍历词元频率\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")  # 打印词元及其出现频率\n",
    "        \n",
    "print_sampled_tokens(probas)  # 调用print_sampled_tokens函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20831bd-1b26-4a62-91b3-256bc24cc994",
   "metadata": {},
   "source": [
    "- 我们可以通过一个称为温度缩放的概念来控制分布和选择过程。\n",
    "- “温度缩放”只是一个花哨的词，意味着将logits除以一个大于0的数字。\n",
    "- 大于1的温度将在应用softmax后导致更均匀分布的标记概率。\n",
    "- 小于1的温度将在应用softmax后导致更尖锐或更高峰的分布。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c4c2771b-38db-47be-9f80-dfd4cc82be15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def softmax_with_temperature(logits, temperature):  # 定义带温度的softmax函数\n",
    "    scaled_logits = logits / temperature  # 对logits进行温度缩放\n",
    "    return torch.softmax(scaled_logits, dim=0)  # 返回softmax结果\n",
    "temperatures = [1, 0.1, 5]  #A 定义温度列表\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]  # 对每个温度计算缩放后的概率\n",
    "x = torch.arange(len(vocab))  # 定义x轴刻度\n",
    "bar_width = 0.15  # 定义柱宽\n",
    "fig, ax = plt.subplots(figsize=(5, 3))  # 创建图形和子图\n",
    "for i, T in enumerate(temperatures):  # 遍历温度列表\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i],  # 绘制柱状图\n",
    "                   bar_width, label=f'Temperature = {T}')\n",
    "ax.set_ylabel('Probability')  # 设置y轴标签为“Probability”\n",
    "ax.set_xticks(x)  # 设置x轴刻度\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)  # 设置x轴刻度标签\n",
    "ax.legend()  # 显示图例\n",
    "plt.tight_layout()  # 调整子图布局\n",
    "plt.show()  # 显示图形"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d18b56-2e1c-4e77-a059-ea000c72eb9e",
   "metadata": {},
   "source": [
    "- 我们可以看到，通过温度0.1的重新缩放导致了一个更尖锐的分布，接近torch.argmax，以至于最可能的单词几乎总是被选中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e163fbfb-4785-4ec6-8ecc-1d04c0684b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "992 x forward\n",
      "0 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "8 x toward\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f77691-e271-4cec-a30d-334cd40d92ca",
   "metadata": {},
   "source": [
    "- 通过温度5重新缩放的概率分布更加均匀："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8d8417ec-c0e7-44b1-bdd2-7c1359b33a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 x closer\n",
      "68 x every\n",
      "55 x effort\n",
      "223 x forward\n",
      "102 x inches\n",
      "50 x moves\n",
      "43 x pizza\n",
      "218 x toward\n",
      "88 x you\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f69bd8-2a68-4bf8-9089-635b9ea7fc6a",
   "metadata": {},
   "source": [
    "- 假设LLM输入为“every effort moves you”，使用上述方法有时会产生无意义的文本，例如“every effort moves you pizza”，占4.3%（1000次中的43次）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8892cf8f-40d7-4322-ba0a-ca3c67d81461",
   "metadata": {},
   "source": [
    "### 5.3.2 Top-k sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc601a1f-246f-47c1-827f-433994c76541",
   "metadata": {},
   "source": [
    "- 为了能够使用更高的温度来增加输出多样性并减少无意义句子的概率，我们可以将采样的标记限制在最可能的top-k个标记中："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8d9556-2aca-46cc-9ac7-b191895efb41",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/topk.webp\" width=500px>\n",
    "\n",
    "- (请注意，为了减少视觉混乱，图中的数字被截断为小数点后两位。Softmax行中的值应该加起来等于1.0。\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d8c944-eea5-4237-a3fc-d0df056b2ab7",
   "metadata": {},
   "source": [
    "- 在代码中，我们可以这样实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "51237358-f242-474c-af4f-ad086eaaa9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3  # 设置top-k为3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)  # 选择具有最大logit值的词元\n",
    "print(\"Top logits:\", top_logits)  # 打印最大logit值\n",
    "print(\"Top positions:\", top_pos)  # 打印最大logit值的位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dbd59912-f263-487f-801e-b20a7f25fe59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(  # 使用where函数更新logits\n",
    "    condition=next_token_logits < top_logits[-1],  #A 确定小于top 3最小值的logits\n",
    "    input=torch.tensor(float('-inf')),  #B 将这些较低的logits赋值为-inf\n",
    "    other=next_token_logits  #C 其他词元保留原始logits\n",
    ")\n",
    "print(new_logits)  # 打印更新后的logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "860f5dea-d925-49d1-947a-6ae2697c4a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)  # 对更新后的logits应用softmax函数\n",
    "print(topk_probas)  # 打印top-k概率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b9828f-7f03-430b-aea0-81064da7c59e",
   "metadata": {},
   "source": [
    "### 5.3.3 Modifying the text generation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b443182f-d104-450e-81eb-ef86d46781aa",
   "metadata": {},
   "source": [
    "- 前两个小节介绍了温度采样和top-k采样。\n",
    "- 让我们使用这两个概念来修改我们之前用来通过LLM生成文本的`generate_simple`函数，创建一个新的`generate`函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "28caf417-3a26-4d21-9d0a-86c634862e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size,  # 定义生成函数\n",
    "             temperature=1.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):  #A 遍历最大新词元数\n",
    "        idx_cond = idx[-context_size:]  # 获取上下文\n",
    "        with torch.no_grad():  # 禁用梯度计算\n",
    "            logits = model(idx_cond)  # 获取模型的logits\n",
    "            logits = logits[:, -1, :]  # 只关注最后一个时间步的logits\n",
    "        if top_k is not None:  #B 在新部分中，使用top-k采样\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,  #A 确定小于top 3最小值的logits\n",
    "                torch.tensor(float('-inf')).to(logits.device),  #B 将这些较低的logits赋值为-inf\n",
    "                logits  #C 其他词元保留原始logits\n",
    "            )\n",
    "\n",
    "        if temperature > 0.0:  #C 这是我们应用温度缩放的新部分\n",
    "            logits = logits / temperature  # 对logits进行温度缩放\n",
    "            probs = torch.softmax(logits, dim=-1)  # 应用softmax函数\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # 使用多项式函数进行采样\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  #D 在禁用温度缩放时执行贪婪选择\n",
    "        if idx_next == eos_id:  #E 如果遇到序列结束词元且指定了eos_id，则提前终止生成\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # 将新词元添加到索引序列中\n",
    "    return idx  # 返回索引序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c184be35-ba52-403c-b86c-3aadf23d5b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know began to my surprise, a little it was the\n",
      "\"Ah enough\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)  # 设置随机种子\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),  # 将文本转换为词元ID并移动到设备\n",
    "    max_new_tokens=15,  # 最大新词元数为15\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],  # 上下文大小\n",
    "    top_k=25,  # top-k值为25\n",
    "    temperature=1.4  # 温度值为1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))  # 打印生成的文本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebad051f-2807-41ac-8009-d4598d45e9db",
   "metadata": {},
   "source": [
    "## 5.4 Loading and saving model weights in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea9cee0-9fe0-4e6c-bdb1-6fec13708507",
   "metadata": {},
   "source": [
    "- 训练LLMs在计算上很昂贵，因此能够保存和加载LLM权重至关重要。\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model-3.webp\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d639eafc-1ac6-4157-beeb-fbc2249bb3ac",
   "metadata": {},
   "source": [
    "- PyTorch中推荐的方式是保存模型权重，即所谓的`state_dict`，通过将`torch.save`函数应用于`.state_dict()`方法来实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ac9dd442-8180-4612-a8c5-5e9a14479681",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")  # 保存模型权重到model.pth文件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f7bda0-867b-4e79-9878-abdc62ab7959",
   "metadata": {},
   "source": [
    "- 然后，我们可以将模型权重加载到一个新的`GPTModel`模型实例中，如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "14d000d9-a820-4c50-ada6-357e8afda155",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xin123456\\AppData\\Local\\Temp\\ipykernel_3036\\1053747252.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"model.pth\"))  # 加载保存的模型权重\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)  # 初始化新模型实例\n",
    "model.load_state_dict(torch.load(\"model.pth\"))  # 加载保存的模型权重\n",
    "model.eval()  # 设置模型为评估模式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8016ab-5f3d-497f-bd25-705f9801cc69",
   "metadata": {},
   "source": [
    "- 使用像Adam或AdamW这样的自适应优化器而不是常规的SGD来训练LLMs是很常见的。\n",
    "- 这些自适应优化器为每个模型权重存储额外的参数，因此，如果我们计划稍后继续预训练，保存它们也是有意义的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2b9ebaf1-9597-48d3-93c9-7f3bccb52294",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({  # 保存模型和优化器的状态字典\n",
    "    \"model_state_dict\": model.state_dict(),  # 模型状态字典\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),  # 优化器状态字典\n",
    "}, \"model_and_optimizer.pth\")  # 保存到model_and_optimizer.pth文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "91ed8c5d-aa02-45a4-9581-8472b3a871ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xin123456\\AppData\\Local\\Temp\\ipykernel_3036\\3763583658.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"model_and_optimizer.pth\")  # 加载保存的检查点\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\")  # 加载保存的检查点\n",
    "model = GPTModel(GPT_CONFIG_124M)  # 初始化新模型实例\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])  # 加载模型状态字典\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)  # 初始化优化器\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])  # 加载优化器状态字典\n",
    "model.train()  # 设置模型为训练模式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ebdcfe-5977-468b-8452-1228cd538b14",
   "metadata": {},
   "source": [
    "## 5.5 Loading pretrained weights from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3eb5a166-d6f8-48f4-b25b-1f85ca1bce6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n",
      "tqdm version: 4.66.4\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", version(\"tensorflow\"))\n",
    "print(\"tqdm version:\", version(\"tqdm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4ff7b5a6-fe98-4ac2-9b9b-416f59bf8a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_download import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "90a81b77-b6b0-436f-82ae-dd7a88fa9347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 68.5kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:05<00:00, 176kiB/s] \n",
      "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 63.8kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [2:15:46<00:00, 61.1kiB/s]  \n",
      "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 1.56MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 471k/471k [00:07<00:00, 63.0kiB/s] \n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:01<00:00, 420kiB/s] \n"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e67c0635-f937-4034-aea5-d7aa04c4677b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)  # 打印设置\n",
    "print(\"Parameter dictionary keys:\", params.keys())  # 打印参数字典键"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75723714-88c3-4111-9793-1e51f193df40",
   "metadata": {},
   "source": [
    "- settings和params都是Python字典:\n",
    "    - settings字典存储LLM架构设置，类似于我们手动定义的GPT_CONFIG_124M设置。\n",
    "    - params字典包含实际的权重张量。\n",
    "- 请注意，我们只打印了字典键，因为打印权重内容会占用太多屏幕空间，但我们可以通过print(params)打印整个字典或通过相应的字典键选择单个张量来检查这些权重张量，例如，嵌入层权重："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "90b3e530-7286-496e-b7ec-a2b1bb9e2e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])  # 打印词元嵌入权重张量\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)  # 打印词元嵌入权重张量的维度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eef262c-487f-4519-a9f7-f87152e8b0d7",
   "metadata": {},
   "source": [
    "- 我们通过`download_and_load_gpt2(model_size=“124M”, …)`设置下载并加载了最小的GPT-2模型的权重。\n",
    "- 请注意，OpenAI还分享了更大模型的权重：“355M”、“774M”和“1558M”。这些不同大小的GPT模型的总体架构是相同的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4376f1-04ab-41d5-ba0b-b08a0c796cd4",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/gpt-sizes.webp?timestamp=123\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c168253-9a1e-4db7-8be6-2103e2d85cb1",
   "metadata": {},
   "source": [
    "- 上面，我们已经将1.24亿参数的GPT-2模型权重加载到了Python中，但是我们仍然需要将它们转移到我们的`GPTModel`实例中。\n",
    "- 首先，我们初始化一个新的 `GPTModel` 实例。\n",
    "- 请注意，原始的GPT模型在多头注意力模块中为查询（query）、键（key）和值（value）矩阵的线性层初始化了带有偏置向量的，这并不是必需的或推荐的；然而，为了能够正确加载权重，在我们的实现中，我们也必须通过将`qkv_bias`设置为`True`来启用这些偏置。\n",
    "- 我们也在使用原始GPT-2模型所采用的`1024`个token的上下文长度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e8ca4f66-d4db-4dc3-9cc8-78b9212cb51b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_configs = {  # 定义模型配置字典\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "model_name = \"gpt2-small (124M)\"  # 选择模型名称\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()  # 复制原始配置\n",
    "NEW_CONFIG.update(model_configs[model_name])  # 更新配置为选定模型的配置\n",
    "NEW_CONFIG.update({\"context_length\": 1024})  # 更新上下文长度为1024\n",
    "NEW_CONFIG.update({\"qkv_bias\": True})  # 启用偏置向量\n",
    "gpt = GPTModel(NEW_CONFIG)  # 使用更新的配置初始化GPT模型\n",
    "gpt.eval()  # 设置模型为评估模式\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)  # 使用更新的配置初始化GPT模型\n",
    "gpt.eval()  # 设置模型为评估模式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feb8bf4-ccbc-46c4-9f6a-0c5399ca0d66",
   "metadata": {},
   "source": [
    "- 接下来的任务是将OpenAI的权重分配到我们`GPTModel`实例中相应的权重张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7a67d864-7aa2-405a-ac31-a224b9789c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):  # 定义assign函数\n",
    "    if left.shape != right.shape:  # 如果形状不匹配\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")  # 抛出错误\n",
    "    return torch.nn.Parameter(torch.tensor(right))  # 返回右张量作为可训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0512bbeb-b874-409b-8d7c-0ba534abaf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "    \n",
    "    \n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec394b1-b692-4f25-8f3c-a682d5cc8a14",
   "metadata": {},
   "source": [
    "- 如果模型加载正确，我们就可以使用先前的`generate`函数来生成新文本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4f0d23e8-e969-4a62-8027-4921f1ca1e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward an equal share for each vote plus half. Inequality is often not an accurate representation of human worth; to know the\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)  # 设置随机种子\n",
    "token_ids = generate(  # 生成新文本\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))  # 打印输出文本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4d71ed-482e-4854-ab67-d5fb3dac8c8e",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3a9ca6-35e2-4741-8297-b2ae8f2a49e9",
   "metadata": {},
   "source": [
    "- 当LLM生成文本时，它们一次输出一个词元。\n",
    "- 默认情况下，下一个词元是通过将模型输出转换为概率分数并从词汇表中选择对应于最高概率分数的词元生成的，这被称为“贪婪解码”。\n",
    "- 使用概率采样和温度缩放，我们可以影响生成文本的多样性和连贯性。\n",
    "- 训练和验证集的损失可用于评估LLM在训练期间生成的文本质量。\n",
    "- 预训练LLM涉及更改其权重以最小化训练损失。\n",
    "- LLM的训练循环本身是深度学习中的标准程序，使用传统的交叉熵损失和AdamW优化器。\n",
    "- 在大型文本语料库上预训练LLM是耗时且资源密集的，因此我们可以加载OpenAI公开可用的权重，作为我们自己在大型数据集上预训练模型的替代方案。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
